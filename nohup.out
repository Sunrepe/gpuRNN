WARNING:tensorflow:From all_three_lstm.py:91: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.
WARNING:tensorflow:From all_three_lstm.py:93: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.
WARNING:tensorflow:From all_three_lstm.py:94: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use tf.cast instead.
WARNING:tensorflow:From all_three_lstm.py:94: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
WARNING:tensorflow:From /home/sunrepe/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/tensor_array_ops.py:162: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From all_three_lstm.py:96: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.
Instructions for updating:
Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.
WARNING:tensorflow:From all_three_lstm.py:97: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.dense instead.
loading data...
['liangxiaohe', 'lihejia', 'makaiyan', 'mayiming', 'pengdongmei', 'shechen', 'shenshenyuan']
train: 6789 test: 1649
load data time: 162.93797993659973
Start train!
Training iter #400:   Batch Loss = 26.824217, Accuracy = 0.11749999970197678
PERFORMANCE ON TEST SET: Batch Loss = 26.33942413330078, Accuracy = 0.18496058881282806
Training iter #2000:   Batch Loss = 25.316368, Accuracy = 0.2775000035762787
PERFORMANCE ON TEST SET: Batch Loss = 24.91714859008789, Accuracy = 0.3147362172603607
Training iter #4000:   Batch Loss = 23.601799, Accuracy = 0.3449999988079071
PERFORMANCE ON TEST SET: Batch Loss = 23.05146026611328, Accuracy = 0.3875075876712799
Training iter #6000:   Batch Loss = 22.091051, Accuracy = 0.39750000834465027
PERFORMANCE ON TEST SET: Batch Loss = 21.241186141967773, Accuracy = 0.41237112879753113
Training iter #8000:   Batch Loss = 20.687035, Accuracy = 0.44749999046325684
PERFORMANCE ON TEST SET: Batch Loss = 19.609878540039062, Accuracy = 0.5306246280670166
Training iter #10000:   Batch Loss = 19.226223, Accuracy = 0.5249999761581421
PERFORMANCE ON TEST SET: Batch Loss = 18.402772903442383, Accuracy = 0.5839902758598328
Training iter #12000:   Batch Loss = 18.403355, Accuracy = 0.6025000214576721
PERFORMANCE ON TEST SET: Batch Loss = 17.533231735229492, Accuracy = 0.5955124497413635
Training iter #14000:   Batch Loss = 17.257101, Accuracy = 0.6200000047683716
PERFORMANCE ON TEST SET: Batch Loss = 16.759479522705078, Accuracy = 0.6246209740638733
Training iter #16000:   Batch Loss = 16.993895, Accuracy = 0.6274999976158142
PERFORMANCE ON TEST SET: Batch Loss = 15.986626625061035, Accuracy = 0.6701030731201172
Training iter #18000:   Batch Loss = 16.145864, Accuracy = 0.6800000071525574
PERFORMANCE ON TEST SET: Batch Loss = 15.258407592773438, Accuracy = 0.676167368888855
Training iter #20000:   Batch Loss = 15.517801, Accuracy = 0.699999988079071
PERFORMANCE ON TEST SET: Batch Loss = 14.80474853515625, Accuracy = 0.7077016234397888
Training iter #22000:   Batch Loss = 14.669808, Accuracy = 0.7450000047683716
PERFORMANCE ON TEST SET: Batch Loss = 14.495383262634277, Accuracy = 0.7064887881278992
Training iter #24000:   Batch Loss = 15.160844, Accuracy = 0.7049999833106995
PERFORMANCE ON TEST SET: Batch Loss = 14.260528564453125, Accuracy = 0.7113401889801025
Training iter #26000:   Batch Loss = 14.776106, Accuracy = 0.7024999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.874654769897461, Accuracy = 0.7289265990257263
Training iter #28000:   Batch Loss = 14.617351, Accuracy = 0.7174999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.592490196228027, Accuracy = 0.7295330762863159
Training iter #30000:   Batch Loss = 13.523647, Accuracy = 0.7724999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.593428611755371, Accuracy = 0.7107337713241577
Training iter #32000:   Batch Loss = 14.420205, Accuracy = 0.7099999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.330228805541992, Accuracy = 0.7228623628616333
Training iter #34000:   Batch Loss = 14.215904, Accuracy = 0.7223650217056274
PERFORMANCE ON TEST SET: Batch Loss = 13.173232078552246, Accuracy = 0.7258945107460022
Training iter #36000:   Batch Loss = 13.340955, Accuracy = 0.7774999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.050300598144531, Accuracy = 0.7471194863319397
Training iter #38000:   Batch Loss = 12.778527, Accuracy = 0.7900000214576721
PERFORMANCE ON TEST SET: Batch Loss = 12.805736541748047, Accuracy = 0.757428765296936
Training iter #40000:   Batch Loss = 12.910496, Accuracy = 0.7574999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.784385681152344, Accuracy = 0.7392358779907227
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-100
Training iter #42000:   Batch Loss = 13.284678, Accuracy = 0.7225000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.863465309143066, Accuracy = 0.755003035068512
Training iter #44000:   Batch Loss = 13.213470, Accuracy = 0.7549999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.734346389770508, Accuracy = 0.7562158703804016
Training iter #46000:   Batch Loss = 12.825618, Accuracy = 0.7699999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.456232070922852, Accuracy = 0.7628865838050842
Training iter #48000:   Batch Loss = 13.212117, Accuracy = 0.7749999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.372220039367676, Accuracy = 0.7428744435310364
Training iter #50000:   Batch Loss = 12.967226, Accuracy = 0.7549999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.980547904968262, Accuracy = 0.7568222880363464
Training iter #52000:   Batch Loss = 13.403406, Accuracy = 0.7599999904632568
PERFORMANCE ON TEST SET: Batch Loss = 13.195670127868652, Accuracy = 0.7604609131813049
Training iter #54000:   Batch Loss = 13.623362, Accuracy = 0.7875000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.274187088012695, Accuracy = 0.7677380442619324
Training iter #56000:   Batch Loss = 13.375279, Accuracy = 0.7900000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.190423965454102, Accuracy = 0.7459065914154053
Training iter #58000:   Batch Loss = 13.005840, Accuracy = 0.7674999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.886555671691895, Accuracy = 0.749545156955719
Training iter #60000:   Batch Loss = 13.159852, Accuracy = 0.8149999976158142
PERFORMANCE ON TEST SET: Batch Loss = 13.01357650756836, Accuracy = 0.7604609131813049
Training iter #62000:   Batch Loss = 13.029647, Accuracy = 0.7875000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.937315940856934, Accuracy = 0.757428765296936
Training iter #64000:   Batch Loss = 13.079173, Accuracy = 0.7749999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.761420249938965, Accuracy = 0.7719830274581909
Training iter #66000:   Batch Loss = 12.339669, Accuracy = 0.8075000047683716
PERFORMANCE ON TEST SET: Batch Loss = 12.658512115478516, Accuracy = 0.7604609131813049
Training iter #68000:   Batch Loss = 12.299392, Accuracy = 0.8200514316558838
PERFORMANCE ON TEST SET: Batch Loss = 12.411920547485352, Accuracy = 0.7889630198478699
Training iter #70000:   Batch Loss = 11.735571, Accuracy = 0.8299999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.227590560913086, Accuracy = 0.7677380442619324
Training iter #72000:   Batch Loss = 12.218081, Accuracy = 0.7950000166893005
PERFORMANCE ON TEST SET: Batch Loss = 12.370102882385254, Accuracy = 0.7798665761947632
Training iter #74000:   Batch Loss = 12.756878, Accuracy = 0.7900000214576721
PERFORMANCE ON TEST SET: Batch Loss = 12.49619197845459, Accuracy = 0.7774408459663391
Training iter #76000:   Batch Loss = 12.185953, Accuracy = 0.7925000190734863
PERFORMANCE ON TEST SET: Batch Loss = 12.390661239624023, Accuracy = 0.7816858887672424
Training iter #78000:   Batch Loss = 11.187960, Accuracy = 0.8450000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.229113578796387, Accuracy = 0.7774408459663391
Training iter #80000:   Batch Loss = 12.242192, Accuracy = 0.7850000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.105796813964844, Accuracy = 0.7871437072753906
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-200
Training iter #82000:   Batch Loss = 11.555645, Accuracy = 0.824999988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.1863431930542, Accuracy = 0.7792601585388184
Training iter #84000:   Batch Loss = 11.718016, Accuracy = 0.824999988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.16939926147461, Accuracy = 0.7816858887672424
Training iter #86000:   Batch Loss = 11.506273, Accuracy = 0.8274999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.224187850952148, Accuracy = 0.7719830274581909
Training iter #88000:   Batch Loss = 11.373087, Accuracy = 0.8199999928474426
PERFORMANCE ON TEST SET: Batch Loss = 11.898502349853516, Accuracy = 0.7926015853881836
Training iter #90000:   Batch Loss = 11.479318, Accuracy = 0.8450000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.009145736694336, Accuracy = 0.780472993850708
Training iter #92000:   Batch Loss = 11.203707, Accuracy = 0.8399999737739563
PERFORMANCE ON TEST SET: Batch Loss = 11.798583030700684, Accuracy = 0.7841115593910217
Training iter #94000:   Batch Loss = 11.124337, Accuracy = 0.8224999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.05707836151123, Accuracy = 0.7731958627700806
Training iter #96000:   Batch Loss = 11.303797, Accuracy = 0.8725000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.1665620803833, Accuracy = 0.799878716468811
Training iter #98000:   Batch Loss = 11.287336, Accuracy = 0.8575000166893005
PERFORMANCE ON TEST SET: Batch Loss = 12.364956855773926, Accuracy = 0.7750151753425598
Training iter #100000:   Batch Loss = 11.752488, Accuracy = 0.8600000143051147
PERFORMANCE ON TEST SET: Batch Loss = 12.257743835449219, Accuracy = 0.780472993850708
Training iter #102000:   Batch Loss = 11.716703, Accuracy = 0.8406169414520264
PERFORMANCE ON TEST SET: Batch Loss = 11.871318817138672, Accuracy = 0.8035172820091248
Training iter #104000:   Batch Loss = 11.015795, Accuracy = 0.875
PERFORMANCE ON TEST SET: Batch Loss = 12.027055740356445, Accuracy = 0.7889630198478699
Training iter #106000:   Batch Loss = 10.967873, Accuracy = 0.8374999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.256315231323242, Accuracy = 0.7792601585388184
Training iter #108000:   Batch Loss = 12.381609, Accuracy = 0.8550000190734863
PERFORMANCE ON TEST SET: Batch Loss = 12.720255851745605, Accuracy = 0.7950273156166077
Training iter #110000:   Batch Loss = 12.777682, Accuracy = 0.8100000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.804303169250488, Accuracy = 0.7707701921463013
Training iter #112000:   Batch Loss = 11.544942, Accuracy = 0.8550000190734863
PERFORMANCE ON TEST SET: Batch Loss = 12.588279724121094, Accuracy = 0.7950273156166077
Training iter #114000:   Batch Loss = 15.316633, Accuracy = 0.8675000071525574
PERFORMANCE ON TEST SET: Batch Loss = 15.958110809326172, Accuracy = 0.766525149345398
Training iter #116000:   Batch Loss = 14.849796, Accuracy = 0.8424999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.695974349975586, Accuracy = 0.7653123140335083
Training iter #118000:   Batch Loss = 12.794764, Accuracy = 0.8799999952316284
PERFORMANCE ON TEST SET: Batch Loss = 13.871891021728516, Accuracy = 0.7956337332725525
Training iter #120000:   Batch Loss = 13.056662, Accuracy = 0.875
PERFORMANCE ON TEST SET: Batch Loss = 13.444428443908691, Accuracy = 0.7968465685844421
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-300
Training iter #122000:   Batch Loss = 12.671298, Accuracy = 0.8550000190734863
PERFORMANCE ON TEST SET: Batch Loss = 13.087898254394531, Accuracy = 0.7877501249313354
Training iter #124000:   Batch Loss = 11.967695, Accuracy = 0.8824999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.256711959838867, Accuracy = 0.7865372896194458
Training iter #126000:   Batch Loss = 11.809340, Accuracy = 0.8949999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.192981719970703, Accuracy = 0.7841115593910217
Training iter #128000:   Batch Loss = 12.094626, Accuracy = 0.8924999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.001174926757812, Accuracy = 0.7750151753425598
Training iter #130000:   Batch Loss = 12.124284, Accuracy = 0.8849999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.84221076965332, Accuracy = 0.7968465685844421
Training iter #132000:   Batch Loss = 12.103823, Accuracy = 0.8849999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.929777145385742, Accuracy = 0.7768344283103943
Training iter #134000:   Batch Loss = 11.492016, Accuracy = 0.8899999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.866154670715332, Accuracy = 0.7792601585388184
Training iter #136000:   Batch Loss = 11.867018, Accuracy = 0.8688945770263672
PERFORMANCE ON TEST SET: Batch Loss = 13.157366752624512, Accuracy = 0.7628865838050842
Training iter #138000:   Batch Loss = 11.674473, Accuracy = 0.8849999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.990730285644531, Accuracy = 0.7907822728157043
Training iter #140000:   Batch Loss = 11.493349, Accuracy = 0.9125000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.773188591003418, Accuracy = 0.7926015853881836
Training iter #142000:   Batch Loss = 11.409080, Accuracy = 0.8849999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.709671020507812, Accuracy = 0.7871437072753906
Training iter #144000:   Batch Loss = 11.635494, Accuracy = 0.875
PERFORMANCE ON TEST SET: Batch Loss = 12.694045066833496, Accuracy = 0.8035172820091248
Training iter #146000:   Batch Loss = 11.268440, Accuracy = 0.9125000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.796451568603516, Accuracy = 0.7774408459663391
Training iter #148000:   Batch Loss = 11.757391, Accuracy = 0.8650000095367432
PERFORMANCE ON TEST SET: Batch Loss = 12.842424392700195, Accuracy = 0.7756215929985046
Training iter #150000:   Batch Loss = 11.623945, Accuracy = 0.8974999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.75483512878418, Accuracy = 0.7877501249313354
Training iter #152000:   Batch Loss = 11.293678, Accuracy = 0.8899999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.604883193969727, Accuracy = 0.780472993850708
Training iter #154000:   Batch Loss = 11.437230, Accuracy = 0.8774999976158142
PERFORMANCE ON TEST SET: Batch Loss = 12.345887184143066, Accuracy = 0.805336594581604
Training iter #156000:   Batch Loss = 11.331544, Accuracy = 0.8924999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.207098960876465, Accuracy = 0.8156458735466003
Training iter #158000:   Batch Loss = 11.172623, Accuracy = 0.8799999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.379915237426758, Accuracy = 0.7841115593910217
Training iter #160000:   Batch Loss = 11.170614, Accuracy = 0.875
PERFORMANCE ON TEST SET: Batch Loss = 12.27629280090332, Accuracy = 0.7822923064231873
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-400
Training iter #162000:   Batch Loss = 12.043756, Accuracy = 0.8774999976158142
PERFORMANCE ON TEST SET: Batch Loss = 13.78172492980957, Accuracy = 0.7610673308372498
Training iter #164000:   Batch Loss = 13.454519, Accuracy = 0.8550000190734863
PERFORMANCE ON TEST SET: Batch Loss = 14.300277709960938, Accuracy = 0.768950879573822
Training iter #166000:   Batch Loss = 12.604074, Accuracy = 0.8799999952316284
PERFORMANCE ON TEST SET: Batch Loss = 13.592387199401855, Accuracy = 0.7713766098022461
Training iter #168000:   Batch Loss = 12.419142, Accuracy = 0.8725000023841858
PERFORMANCE ON TEST SET: Batch Loss = 13.350759506225586, Accuracy = 0.7822923064231873
Training iter #170000:   Batch Loss = 12.864204, Accuracy = 0.8534704446792603
PERFORMANCE ON TEST SET: Batch Loss = 13.84437084197998, Accuracy = 0.7707701921463013
Training iter #172000:   Batch Loss = 12.484224, Accuracy = 0.887499988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.689671516418457, Accuracy = 0.7980594038963318
Training iter #174000:   Batch Loss = 12.508965, Accuracy = 0.8999999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.347654342651367, Accuracy = 0.7944208383560181
Training iter #176000:   Batch Loss = 12.338812, Accuracy = 0.887499988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.144096374511719, Accuracy = 0.7853244543075562
Training iter #178000:   Batch Loss = 11.581944, Accuracy = 0.875
PERFORMANCE ON TEST SET: Batch Loss = 13.027580261230469, Accuracy = 0.8071558475494385
Training iter #180000:   Batch Loss = 11.819212, Accuracy = 0.8974999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.176775932312012, Accuracy = 0.7944208383560181
Training iter #182000:   Batch Loss = 12.210550, Accuracy = 0.9024999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.962666511535645, Accuracy = 0.7889630198478699
Training iter #184000:   Batch Loss = 12.520531, Accuracy = 0.8575000166893005
PERFORMANCE ON TEST SET: Batch Loss = 12.952217102050781, Accuracy = 0.7919951677322388
Training iter #186000:   Batch Loss = 11.553163, Accuracy = 0.8974999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.975008010864258, Accuracy = 0.7926015853881836
Training iter #188000:   Batch Loss = 11.894116, Accuracy = 0.8450000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.872068405151367, Accuracy = 0.7822923064231873
Training iter #190000:   Batch Loss = 12.004539, Accuracy = 0.8774999976158142
PERFORMANCE ON TEST SET: Batch Loss = 12.894655227661133, Accuracy = 0.7822923064231873
Training iter #192000:   Batch Loss = 11.758358, Accuracy = 0.8575000166893005
PERFORMANCE ON TEST SET: Batch Loss = 12.491275787353516, Accuracy = 0.788356602191925
Training iter #194000:   Batch Loss = 11.342171, Accuracy = 0.9125000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.558023452758789, Accuracy = 0.7992722988128662
Training iter #196000:   Batch Loss = 10.876614, Accuracy = 0.8999999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.428483963012695, Accuracy = 0.797452986240387
Training iter #198000:   Batch Loss = 10.653036, Accuracy = 0.9100000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.441764831542969, Accuracy = 0.7853244543075562
Training iter #200000:   Batch Loss = 10.912278, Accuracy = 0.8974999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.384683609008789, Accuracy = 0.7950273156166077
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-500
Training iter #202000:   Batch Loss = 11.335043, Accuracy = 0.8974999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.448320388793945, Accuracy = 0.7980594038963318
Training iter #204000:   Batch Loss = 11.232903, Accuracy = 0.8766067028045654
PERFORMANCE ON TEST SET: Batch Loss = 12.44890022277832, Accuracy = 0.7926015853881836
Training iter #206000:   Batch Loss = 11.349336, Accuracy = 0.8675000071525574
PERFORMANCE ON TEST SET: Batch Loss = 12.586358070373535, Accuracy = 0.7865372896194458
Training iter #208000:   Batch Loss = 11.376727, Accuracy = 0.8974999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.648662567138672, Accuracy = 0.7932080030441284
Training iter #210000:   Batch Loss = 10.713849, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.472451210021973, Accuracy = 0.7841115593910217
Training iter #212000:   Batch Loss = 10.938261, Accuracy = 0.8924999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.62563705444336, Accuracy = 0.7926015853881836
Training iter #214000:   Batch Loss = 11.351398, Accuracy = 0.887499988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.742734909057617, Accuracy = 0.7895694375038147
Training iter #216000:   Batch Loss = 11.160972, Accuracy = 0.887499988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.567123413085938, Accuracy = 0.7962401509284973
Training iter #218000:   Batch Loss = 11.025444, Accuracy = 0.9175000190734863
PERFORMANCE ON TEST SET: Batch Loss = 12.965425491333008, Accuracy = 0.7877501249313354
Training iter #220000:   Batch Loss = 11.202876, Accuracy = 0.9049999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.860933303833008, Accuracy = 0.7768344283103943
Training iter #222000:   Batch Loss = 11.616206, Accuracy = 0.8849999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.751453399658203, Accuracy = 0.8004851341247559
Training iter #224000:   Batch Loss = 10.864234, Accuracy = 0.9100000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.440648078918457, Accuracy = 0.8029108643531799
Training iter #226000:   Batch Loss = 11.228684, Accuracy = 0.8949999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.415915489196777, Accuracy = 0.8023044466972351
Training iter #228000:   Batch Loss = 10.853447, Accuracy = 0.9100000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.406304359436035, Accuracy = 0.7986658811569214
Training iter #230000:   Batch Loss = 10.722618, Accuracy = 0.8999999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.298616409301758, Accuracy = 0.7986658811569214
Training iter #232000:   Batch Loss = 10.724748, Accuracy = 0.9075000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.539532661437988, Accuracy = 0.788356602191925
Training iter #234000:   Batch Loss = 10.631485, Accuracy = 0.8999999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.494660377502441, Accuracy = 0.7877501249313354
Training iter #236000:   Batch Loss = 10.593273, Accuracy = 0.9125000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.303544998168945, Accuracy = 0.8016979694366455
Training iter #238000:   Batch Loss = 10.812391, Accuracy = 0.8766067028045654
PERFORMANCE ON TEST SET: Batch Loss = 12.471254348754883, Accuracy = 0.7847180366516113
Training iter #240000:   Batch Loss = 9.900074, Accuracy = 0.9200000166893005
PERFORMANCE ON TEST SET: Batch Loss = 12.367198944091797, Accuracy = 0.7786537408828735
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-600
Training iter #242000:   Batch Loss = 11.157917, Accuracy = 0.8700000047683716
PERFORMANCE ON TEST SET: Batch Loss = 12.829069137573242, Accuracy = 0.7586416006088257
Training iter #244000:   Batch Loss = 11.394917, Accuracy = 0.8824999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.330549240112305, Accuracy = 0.8101879954338074
Training iter #246000:   Batch Loss = 10.739062, Accuracy = 0.887499988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.51929759979248, Accuracy = 0.7986658811569214
Training iter #248000:   Batch Loss = 11.195781, Accuracy = 0.8725000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.604341506958008, Accuracy = 0.7968465685844421
Training iter #250000:   Batch Loss = 11.705956, Accuracy = 0.8650000095367432
PERFORMANCE ON TEST SET: Batch Loss = 13.02511215209961, Accuracy = 0.7865372896194458
Training iter #252000:   Batch Loss = 11.609474, Accuracy = 0.887499988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.071560859680176, Accuracy = 0.7762280106544495
Training iter #254000:   Batch Loss = 11.475951, Accuracy = 0.8899999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.80642032623291, Accuracy = 0.7895694375038147
Training iter #256000:   Batch Loss = 11.279945, Accuracy = 0.8899999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.521299362182617, Accuracy = 0.7889630198478699
Training iter #258000:   Batch Loss = 11.373661, Accuracy = 0.8974999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.72214126586914, Accuracy = 0.7919951677322388
Training iter #260000:   Batch Loss = 10.772229, Accuracy = 0.8799999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.408390045166016, Accuracy = 0.797452986240387
Training iter #262000:   Batch Loss = 11.467494, Accuracy = 0.8475000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.405542373657227, Accuracy = 0.7926015853881836
Training iter #264000:   Batch Loss = 10.879725, Accuracy = 0.8924999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.565006256103516, Accuracy = 0.7865372896194458
Training iter #266000:   Batch Loss = 10.250038, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.38233470916748, Accuracy = 0.7889630198478699
Training iter #268000:   Batch Loss = 10.546969, Accuracy = 0.8949999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.345367431640625, Accuracy = 0.8144329786300659
Training iter #270000:   Batch Loss = 10.711399, Accuracy = 0.8949999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.436773300170898, Accuracy = 0.8023044466972351
Training iter #272000:   Batch Loss = 10.477660, Accuracy = 0.9203084707260132
PERFORMANCE ON TEST SET: Batch Loss = 12.624244689941406, Accuracy = 0.7853244543075562
Training iter #274000:   Batch Loss = 10.449471, Accuracy = 0.9100000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.274347305297852, Accuracy = 0.8059430122375488
Training iter #276000:   Batch Loss = 10.151079, Accuracy = 0.9200000166893005
PERFORMANCE ON TEST SET: Batch Loss = 12.336610794067383, Accuracy = 0.7962401509284973
Training iter #278000:   Batch Loss = 10.208674, Accuracy = 0.9150000214576721
PERFORMANCE ON TEST SET: Batch Loss = 12.202770233154297, Accuracy = 0.799878716468811
Training iter #280000:   Batch Loss = 10.215522, Accuracy = 0.8949999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.044164657592773, Accuracy = 0.7986658811569214
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-700
Training iter #282000:   Batch Loss = 10.192419, Accuracy = 0.9125000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.13879680633545, Accuracy = 0.797452986240387
Training iter #284000:   Batch Loss = 9.769088, Accuracy = 0.9175000190734863
PERFORMANCE ON TEST SET: Batch Loss = 12.188340187072754, Accuracy = 0.7944208383560181
Training iter #286000:   Batch Loss = 10.057451, Accuracy = 0.8974999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.104449272155762, Accuracy = 0.8065494298934937
Training iter #288000:   Batch Loss = 10.212688, Accuracy = 0.9125000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.152121543884277, Accuracy = 0.791388750076294
Training iter #290000:   Batch Loss = 10.086349, Accuracy = 0.925000011920929
PERFORMANCE ON TEST SET: Batch Loss = 12.387656211853027, Accuracy = 0.7919951677322388
Training iter #292000:   Batch Loss = 10.045520, Accuracy = 0.9024999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.391838073730469, Accuracy = 0.788356602191925
Training iter #294000:   Batch Loss = 10.304705, Accuracy = 0.8999999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.274301528930664, Accuracy = 0.8083686828613281
Training iter #296000:   Batch Loss = 9.890178, Accuracy = 0.9200000166893005
PERFORMANCE ON TEST SET: Batch Loss = 12.212331771850586, Accuracy = 0.7889630198478699
Training iter #298000:   Batch Loss = 9.794658, Accuracy = 0.9024999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.03053092956543, Accuracy = 0.8083686828613281
Training iter #300000:   Batch Loss = 9.863014, Accuracy = 0.925000011920929
PERFORMANCE ON TEST SET: Batch Loss = 12.267860412597656, Accuracy = 0.7932080030441284
Training iter #302000:   Batch Loss = 9.876541, Accuracy = 0.9075000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.350120544433594, Accuracy = 0.7932080030441284
Training iter #304000:   Batch Loss = 10.564009, Accuracy = 0.9225000143051147
PERFORMANCE ON TEST SET: Batch Loss = 12.49472427368164, Accuracy = 0.774408757686615
Training iter #306000:   Batch Loss = 10.115750, Accuracy = 0.9151670932769775
PERFORMANCE ON TEST SET: Batch Loss = 12.207220077514648, Accuracy = 0.8089751601219177
Training iter #308000:   Batch Loss = 9.713322, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 12.055255889892578, Accuracy = 0.8107944130897522
Training iter #310000:   Batch Loss = 10.399421, Accuracy = 0.9024999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.113975524902344, Accuracy = 0.8023044466972351
Training iter #312000:   Batch Loss = 10.433126, Accuracy = 0.8999999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.11899185180664, Accuracy = 0.7889630198478699
Training iter #314000:   Batch Loss = 10.154977, Accuracy = 0.9024999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.301804542541504, Accuracy = 0.8150393962860107
Training iter #316000:   Batch Loss = 10.784220, Accuracy = 0.862500011920929
PERFORMANCE ON TEST SET: Batch Loss = 12.269824981689453, Accuracy = 0.799878716468811
Training iter #318000:   Batch Loss = 10.023809, Accuracy = 0.9100000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.114226341247559, Accuracy = 0.811400830745697
Training iter #320000:   Batch Loss = 10.183559, Accuracy = 0.9049999713897705
PERFORMANCE ON TEST SET: Batch Loss = 11.9981107711792, Accuracy = 0.8041236996650696
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-800
Training iter #322000:   Batch Loss = 9.865137, Accuracy = 0.9024999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.045010566711426, Accuracy = 0.8010915517807007
Training iter #324000:   Batch Loss = 9.509296, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.037335395812988, Accuracy = 0.8010915517807007
Training iter #326000:   Batch Loss = 9.947192, Accuracy = 0.9100000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.126567840576172, Accuracy = 0.7962401509284973
Training iter #328000:   Batch Loss = 9.556562, Accuracy = 0.925000011920929
PERFORMANCE ON TEST SET: Batch Loss = 12.171724319458008, Accuracy = 0.8023044466972351
Training iter #330000:   Batch Loss = 9.743852, Accuracy = 0.9024999737739563
PERFORMANCE ON TEST SET: Batch Loss = 11.847856521606445, Accuracy = 0.8198908567428589
Training iter #332000:   Batch Loss = 9.150146, Accuracy = 0.9150000214576721
PERFORMANCE ON TEST SET: Batch Loss = 11.79223346710205, Accuracy = 0.8162522912025452
Training iter #334000:   Batch Loss = 9.671825, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.075955390930176, Accuracy = 0.8035172820091248
Training iter #336000:   Batch Loss = 10.206916, Accuracy = 0.8999999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.341434478759766, Accuracy = 0.7919951677322388
Training iter #338000:   Batch Loss = 9.536597, Accuracy = 0.9225000143051147
PERFORMANCE ON TEST SET: Batch Loss = 11.90772533416748, Accuracy = 0.8126137256622314
Training iter #340000:   Batch Loss = 9.647469, Accuracy = 0.9048843383789062
PERFORMANCE ON TEST SET: Batch Loss = 11.980777740478516, Accuracy = 0.8059430122375488
Training iter #342000:   Batch Loss = 9.923450, Accuracy = 0.9100000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.193230628967285, Accuracy = 0.7968465685844421
Training iter #344000:   Batch Loss = 9.591417, Accuracy = 0.9075000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.142524719238281, Accuracy = 0.8035172820091248
Training iter #346000:   Batch Loss = 9.455019, Accuracy = 0.9275000095367432
PERFORMANCE ON TEST SET: Batch Loss = 11.954107284545898, Accuracy = 0.8174651265144348
Training iter #348000:   Batch Loss = 9.765490, Accuracy = 0.9125000238418579
PERFORMANCE ON TEST SET: Batch Loss = 11.961400985717773, Accuracy = 0.8023044466972351
Training iter #350000:   Batch Loss = 8.626003, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 12.0624418258667, Accuracy = 0.7986658811569214
Training iter #352000:   Batch Loss = 9.267920, Accuracy = 0.9275000095367432
PERFORMANCE ON TEST SET: Batch Loss = 11.893034934997559, Accuracy = 0.81685870885849
Training iter #354000:   Batch Loss = 9.466487, Accuracy = 0.925000011920929
PERFORMANCE ON TEST SET: Batch Loss = 11.846871376037598, Accuracy = 0.8204972743988037
Training iter #356000:   Batch Loss = 9.685715, Accuracy = 0.9125000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.139867782592773, Accuracy = 0.8023044466972351
Training iter #358000:   Batch Loss = 9.195303, Accuracy = 0.9024999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.087910652160645, Accuracy = 0.8077622652053833
Training iter #360000:   Batch Loss = 9.060488, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 12.023984909057617, Accuracy = 0.8132201433181763
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-900
Training iter #362000:   Batch Loss = 9.041105, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.109251976013184, Accuracy = 0.8029108643531799
Training iter #364000:   Batch Loss = 9.132409, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.029541969299316, Accuracy = 0.8241358399391174
Training iter #366000:   Batch Loss = 10.215791, Accuracy = 0.9150000214576721
PERFORMANCE ON TEST SET: Batch Loss = 12.444939613342285, Accuracy = 0.8077622652053833
Training iter #368000:   Batch Loss = 10.223208, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.625927925109863, Accuracy = 0.8174651265144348
Training iter #370000:   Batch Loss = 10.826702, Accuracy = 0.9075000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.971747398376465, Accuracy = 0.7944208383560181
Training iter #372000:   Batch Loss = 10.180943, Accuracy = 0.9200000166893005
PERFORMANCE ON TEST SET: Batch Loss = 12.468416213989258, Accuracy = 0.7968465685844421
Training iter #374000:   Batch Loss = 9.785352, Accuracy = 0.9383033514022827
PERFORMANCE ON TEST SET: Batch Loss = 12.303889274597168, Accuracy = 0.7992722988128662
Training iter #376000:   Batch Loss = 9.783687, Accuracy = 0.9225000143051147
PERFORMANCE ON TEST SET: Batch Loss = 12.20341968536377, Accuracy = 0.8035172820091248
Training iter #378000:   Batch Loss = 9.919250, Accuracy = 0.9225000143051147
PERFORMANCE ON TEST SET: Batch Loss = 12.021736145019531, Accuracy = 0.8077622652053833
Training iter #380000:   Batch Loss = 9.573835, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 11.919548034667969, Accuracy = 0.8071558475494385
Training iter #382000:   Batch Loss = 9.490675, Accuracy = 0.9150000214576721
PERFORMANCE ON TEST SET: Batch Loss = 12.353158950805664, Accuracy = 0.8041236996650696
Training iter #384000:   Batch Loss = 10.323995, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 12.514004707336426, Accuracy = 0.7986658811569214
Training iter #386000:   Batch Loss = 9.770517, Accuracy = 0.9325000047683716
PERFORMANCE ON TEST SET: Batch Loss = 12.430129051208496, Accuracy = 0.788356602191925
Training iter #388000:   Batch Loss = 9.636309, Accuracy = 0.9325000047683716
PERFORMANCE ON TEST SET: Batch Loss = 12.411617279052734, Accuracy = 0.7956337332725525
Training iter #390000:   Batch Loss = 9.982704, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.215493202209473, Accuracy = 0.799878716468811
Training iter #392000:   Batch Loss = 10.019273, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 11.998634338378906, Accuracy = 0.8150393962860107
Training iter #394000:   Batch Loss = 9.769178, Accuracy = 0.9200000166893005
PERFORMANCE ON TEST SET: Batch Loss = 12.208209991455078, Accuracy = 0.8138265609741211
Training iter #396000:   Batch Loss = 9.615051, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 12.452775001525879, Accuracy = 0.8041236996650696
Training iter #398000:   Batch Loss = 9.185191, Accuracy = 0.9225000143051147
PERFORMANCE ON TEST SET: Batch Loss = 12.418326377868652, Accuracy = 0.7950273156166077
Training iter #400000:   Batch Loss = 10.176073, Accuracy = 0.9200000166893005
PERFORMANCE ON TEST SET: Batch Loss = 12.190669059753418, Accuracy = 0.8192844390869141
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-1000
Training iter #402000:   Batch Loss = 9.804290, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 12.562615394592285, Accuracy = 0.7707701921463013
Training iter #404000:   Batch Loss = 9.814428, Accuracy = 0.9024999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.475018501281738, Accuracy = 0.8101879954338074
Training iter #406000:   Batch Loss = 10.864178, Accuracy = 0.9200000166893005
PERFORMANCE ON TEST SET: Batch Loss = 13.71768856048584, Accuracy = 0.7713766098022461
Training iter #408000:   Batch Loss = 10.785054, Accuracy = 0.9280205368995667
PERFORMANCE ON TEST SET: Batch Loss = 13.154011726379395, Accuracy = 0.805336594581604
Training iter #410000:   Batch Loss = 10.355093, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 13.162982940673828, Accuracy = 0.7938144207000732
Training iter #412000:   Batch Loss = 10.412893, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 13.097874641418457, Accuracy = 0.7962401509284973
Training iter #414000:   Batch Loss = 9.887394, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.689851760864258, Accuracy = 0.811400830745697
Training iter #416000:   Batch Loss = 10.187156, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.603872299194336, Accuracy = 0.8016979694366455
Training iter #418000:   Batch Loss = 10.092811, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.6114501953125, Accuracy = 0.8004851341247559
Training iter #420000:   Batch Loss = 9.599730, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.616195678710938, Accuracy = 0.8101879954338074
Training iter #422000:   Batch Loss = 9.695808, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 12.30262565612793, Accuracy = 0.811400830745697
Training iter #424000:   Batch Loss = 9.973827, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.613441467285156, Accuracy = 0.7853244543075562
Training iter #426000:   Batch Loss = 9.650345, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.779350280761719, Accuracy = 0.8016979694366455
Training iter #428000:   Batch Loss = 9.830728, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 12.456219673156738, Accuracy = 0.81685870885849
Training iter #430000:   Batch Loss = 10.308338, Accuracy = 0.9275000095367432
PERFORMANCE ON TEST SET: Batch Loss = 12.88319206237793, Accuracy = 0.8035172820091248
Training iter #432000:   Batch Loss = 9.895161, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.734193801879883, Accuracy = 0.8041236996650696
Training iter #434000:   Batch Loss = 10.042715, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 12.659543991088867, Accuracy = 0.811400830745697
Training iter #436000:   Batch Loss = 10.124301, Accuracy = 0.9150000214576721
PERFORMANCE ON TEST SET: Batch Loss = 12.778336524963379, Accuracy = 0.7956337332725525
Training iter #438000:   Batch Loss = 9.447145, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.593339920043945, Accuracy = 0.8132201433181763
Training iter #440000:   Batch Loss = 10.107057, Accuracy = 0.9225000143051147
PERFORMANCE ON TEST SET: Batch Loss = 12.676403045654297, Accuracy = 0.8004851341247559
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-1100
Training iter #442000:   Batch Loss = 10.470724, Accuracy = 0.9305912852287292
PERFORMANCE ON TEST SET: Batch Loss = 13.341014862060547, Accuracy = 0.7719830274581909
Training iter #444000:   Batch Loss = 10.008232, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.736421585083008, Accuracy = 0.8041236996650696
Training iter #446000:   Batch Loss = 10.053501, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.768333435058594, Accuracy = 0.8041236996650696
Training iter #448000:   Batch Loss = 10.200859, Accuracy = 0.9175000190734863
PERFORMANCE ON TEST SET: Batch Loss = 12.535789489746094, Accuracy = 0.797452986240387
Training iter #450000:   Batch Loss = 9.704335, Accuracy = 0.9225000143051147
PERFORMANCE ON TEST SET: Batch Loss = 12.455968856811523, Accuracy = 0.799878716468811
Training iter #452000:   Batch Loss = 9.662738, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.345447540283203, Accuracy = 0.7938144207000732
Training iter #454000:   Batch Loss = 9.519986, Accuracy = 0.9049999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.240474700927734, Accuracy = 0.8095815777778625
Training iter #456000:   Batch Loss = 8.876381, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.42836856842041, Accuracy = 0.8010915517807007
Training iter #458000:   Batch Loss = 9.050867, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.348041534423828, Accuracy = 0.7926015853881836
Training iter #460000:   Batch Loss = 9.249197, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 12.146676063537598, Accuracy = 0.8083686828613281
Training iter #462000:   Batch Loss = 9.234762, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.402503967285156, Accuracy = 0.7919951677322388
Training iter #464000:   Batch Loss = 9.331045, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.21738338470459, Accuracy = 0.8047301173210144
Training iter #466000:   Batch Loss = 9.233553, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 12.636682510375977, Accuracy = 0.788356602191925
Training iter #468000:   Batch Loss = 9.233596, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 12.381616592407227, Accuracy = 0.797452986240387
Training iter #470000:   Batch Loss = 9.080062, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.377935409545898, Accuracy = 0.8107944130897522
Training iter #472000:   Batch Loss = 9.233907, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.293736457824707, Accuracy = 0.8156458735466003
Training iter #474000:   Batch Loss = 9.828316, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 12.27010440826416, Accuracy = 0.8107944130897522
Training iter #476000:   Batch Loss = 9.707386, Accuracy = 0.9203084707260132
PERFORMANCE ON TEST SET: Batch Loss = 12.564000129699707, Accuracy = 0.8059430122375488
Training iter #478000:   Batch Loss = 9.565639, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.361851692199707, Accuracy = 0.805336594581604
Training iter #480000:   Batch Loss = 9.517056, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.478086471557617, Accuracy = 0.8023044466972351
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-1200
Training iter #482000:   Batch Loss = 8.754889, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.313544273376465, Accuracy = 0.8132201433181763
Training iter #484000:   Batch Loss = 9.674923, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 12.13766860961914, Accuracy = 0.8126137256622314WARNING:tensorflow:From /home/sunrepe/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.

Training iter #486000:   Batch Loss = 9.009107, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.403838157653809, Accuracy = 0.7853244543075562
Training iter #488000:   Batch Loss = 9.050869, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 11.950669288635254, Accuracy = 0.8162522912025452
Training iter #490000:   Batch Loss = 8.924640, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.06540298461914, Accuracy = 0.7956337332725525
Training iter #492000:   Batch Loss = 9.058759, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.100692749023438, Accuracy = 0.8047301173210144
Training iter #494000:   Batch Loss = 9.121970, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.142040252685547, Accuracy = 0.805336594581604
Training iter #496000:   Batch Loss = 9.543941, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.476534843444824, Accuracy = 0.8010915517807007
Training iter #498000:   Batch Loss = 9.391975, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.61279296875, Accuracy = 0.8126137256622314
Training iter #500000:   Batch Loss = 9.040455, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.319923400878906, Accuracy = 0.8095815777778625
Training iter #502000:   Batch Loss = 9.066228, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.429862976074219, Accuracy = 0.7968465685844421
Training iter #504000:   Batch Loss = 8.927814, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.090229988098145, Accuracy = 0.8198908567428589
Training iter #506000:   Batch Loss = 8.798430, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.217254638671875, Accuracy = 0.8083686828613281
Training iter #508000:   Batch Loss = 8.953277, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.243491172790527, Accuracy = 0.799878716468811
Training iter #510000:   Batch Loss = 9.450077, Accuracy = 0.9537274837493896
PERFORMANCE ON TEST SET: Batch Loss = 12.335719108581543, Accuracy = 0.811400830745697
Training iter #512000:   Batch Loss = 9.598545, Accuracy = 0.9325000047683716
PERFORMANCE ON TEST SET: Batch Loss = 12.262672424316406, Accuracy = 0.8077622652053833
Training iter #514000:   Batch Loss = 9.038378, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.276543617248535, Accuracy = 0.8107944130897522
Training iter #516000:   Batch Loss = 8.918742, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.27332592010498, Accuracy = 0.8138265609741211
Training iter #518000:   Batch Loss = 9.699495, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.694611549377441, Accuracy = 0.7853244543075562
Training iter #520000:   Batch Loss = 9.896771, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 13.236564636230469, Accuracy = 0.7944208383560181
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-1300
Training iter #522000:   Batch Loss = 10.190788, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 13.065492630004883, Accuracy = 0.8016979694366455
Training iter #524000:   Batch Loss = 9.830066, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.72149658203125, Accuracy = 0.8016979694366455
Training iter #526000:   Batch Loss = 9.936959, Accuracy = 0.9175000190734863
PERFORMANCE ON TEST SET: Batch Loss = 12.944326400756836, Accuracy = 0.8041236996650696
Training iter #528000:   Batch Loss = 9.744650, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 12.727011680603027, Accuracy = 0.7938144207000732
Training iter #530000:   Batch Loss = 9.986736, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 12.625407218933105, Accuracy = 0.8132201433181763
Training iter #532000:   Batch Loss = 9.630825, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.751180648803711, Accuracy = 0.8065494298934937
Training iter #534000:   Batch Loss = 9.674747, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 12.920356750488281, Accuracy = 0.8047301173210144
Training iter #536000:   Batch Loss = 9.756341, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.791254043579102, Accuracy = 0.8071558475494385
Training iter #538000:   Batch Loss = 9.634328, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 12.798637390136719, Accuracy = 0.7907822728157043
Training iter #540000:   Batch Loss = 9.347450, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.644415855407715, Accuracy = 0.7986658811569214
Training iter #542000:   Batch Loss = 9.693424, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.953433990478516, Accuracy = 0.8035172820091248
Training iter #544000:   Batch Loss = 9.986392, Accuracy = 0.9383033514022827
PERFORMANCE ON TEST SET: Batch Loss = 12.84935188293457, Accuracy = 0.7926015853881836
Training iter #546000:   Batch Loss = 8.808270, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.471229553222656, Accuracy = 0.8120072484016418
Training iter #548000:   Batch Loss = 9.108807, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.737532615661621, Accuracy = 0.7938144207000732
Training iter #550000:   Batch Loss = 9.639421, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.608795166015625, Accuracy = 0.8004851341247559
Training iter #552000:   Batch Loss = 9.290646, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.712610244750977, Accuracy = 0.797452986240387
Training iter #554000:   Batch Loss = 9.740584, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 12.436737060546875, Accuracy = 0.805336594581604
Training iter #556000:   Batch Loss = 9.123264, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.596490859985352, Accuracy = 0.7816858887672424
Training iter #558000:   Batch Loss = 9.655497, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.896560668945312, Accuracy = 0.7919951677322388
Training iter #560000:   Batch Loss = 9.409710, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.721375465393066, Accuracy = 0.811400830745697
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-1400
Training iter #562000:   Batch Loss = 9.546655, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.807886123657227, Accuracy = 0.7950273156166077
Training iter #564000:   Batch Loss = 9.832159, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.09531307220459, Accuracy = 0.8029108643531799
Training iter #566000:   Batch Loss = 9.736784, Accuracy = 0.9325000047683716
PERFORMANCE ON TEST SET: Batch Loss = 12.767742156982422, Accuracy = 0.8065494298934937
Training iter #568000:   Batch Loss = 9.730672, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.532991409301758, Accuracy = 0.7962401509284973
Training iter #570000:   Batch Loss = 9.929390, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 12.565103530883789, Accuracy = 0.8041236996650696
Training iter #572000:   Batch Loss = 9.660144, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.754249572753906, Accuracy = 0.7938144207000732
Training iter #574000:   Batch Loss = 9.959123, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.806059837341309, Accuracy = 0.7907822728157043
Training iter #576000:   Batch Loss = 9.818319, Accuracy = 0.9325000047683716
PERFORMANCE ON TEST SET: Batch Loss = 12.512004852294922, Accuracy = 0.7907822728157043
Training iter #578000:   Batch Loss = 9.810948, Accuracy = 0.9331619739532471
PERFORMANCE ON TEST SET: Batch Loss = 12.426153182983398, Accuracy = 0.8029108643531799
Training iter #580000:   Batch Loss = 10.523400, Accuracy = 0.9325000047683716
PERFORMANCE ON TEST SET: Batch Loss = 13.082270622253418, Accuracy = 0.8120072484016418
Training iter #582000:   Batch Loss = 10.897346, Accuracy = 0.9325000047683716
PERFORMANCE ON TEST SET: Batch Loss = 13.113077163696289, Accuracy = 0.8016979694366455
Training iter #584000:   Batch Loss = 10.435436, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.9074125289917, Accuracy = 0.8035172820091248
Training iter #586000:   Batch Loss = 9.974441, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.970328330993652, Accuracy = 0.7926015853881836
Training iter #588000:   Batch Loss = 9.865507, Accuracy = 0.925000011920929
PERFORMANCE ON TEST SET: Batch Loss = 12.693456649780273, Accuracy = 0.7992722988128662
Training iter #590000:   Batch Loss = 9.874048, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 12.635047912597656, Accuracy = 0.7853244543075562
Training iter #592000:   Batch Loss = 9.903733, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.748223304748535, Accuracy = 0.8035172820091248
Training iter #594000:   Batch Loss = 9.657368, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.672712326049805, Accuracy = 0.8016979694366455
Training iter #596000:   Batch Loss = 10.618544, Accuracy = 0.9225000143051147
PERFORMANCE ON TEST SET: Batch Loss = 13.107001304626465, Accuracy = 0.8004851341247559
Training iter #598000:   Batch Loss = 9.749526, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 13.104399681091309, Accuracy = 0.7944208383560181
Training iter #600000:   Batch Loss = 10.425080, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 13.303125381469727, Accuracy = 0.7822923064231873
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-1500
Training iter #602000:   Batch Loss = 9.980295, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.866409301757812, Accuracy = 0.8204972743988037
Training iter #604000:   Batch Loss = 9.948503, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.904510498046875, Accuracy = 0.8029108643531799
Training iter #606000:   Batch Loss = 10.007727, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 12.811250686645508, Accuracy = 0.788356602191925
Training iter #608000:   Batch Loss = 9.846977, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.526969909667969, Accuracy = 0.8041236996650696
Training iter #610000:   Batch Loss = 9.647536, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.585550308227539, Accuracy = 0.7865372896194458
Training iter #612000:   Batch Loss = 10.217083, Accuracy = 0.9511567950248718
PERFORMANCE ON TEST SET: Batch Loss = 13.237127304077148, Accuracy = 0.8004851341247559
Training iter #614000:   Batch Loss = 9.819807, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.05520248413086, Accuracy = 0.8035172820091248
Training iter #616000:   Batch Loss = 9.955367, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.615696907043457, Accuracy = 0.8101879954338074
Training iter #618000:   Batch Loss = 9.563947, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.777649879455566, Accuracy = 0.7798665761947632
Training iter #620000:   Batch Loss = 9.626742, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 12.709224700927734, Accuracy = 0.7980594038963318
Training iter #622000:   Batch Loss = 9.608439, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.57184886932373, Accuracy = 0.7992722988128662
Training iter #624000:   Batch Loss = 9.980937, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 12.64909553527832, Accuracy = 0.7986658811569214
Training iter #626000:   Batch Loss = 9.291157, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.316343307495117, Accuracy = 0.8010915517807007
Training iter #628000:   Batch Loss = 9.280406, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.452494621276855, Accuracy = 0.7986658811569214
Training iter #630000:   Batch Loss = 9.627625, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.813897132873535, Accuracy = 0.8156458735466003
Training iter #632000:   Batch Loss = 9.709708, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.75713062286377, Accuracy = 0.8089751601219177
Training iter #634000:   Batch Loss = 8.771000, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.727699279785156, Accuracy = 0.8004851341247559
Training iter #636000:   Batch Loss = 9.461988, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.934381484985352, Accuracy = 0.8016979694366455
Training iter #638000:   Batch Loss = 9.133925, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.677093505859375, Accuracy = 0.799878716468811
Training iter #640000:   Batch Loss = 9.166157, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.46495246887207, Accuracy = 0.805336594581604
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-1600
Training iter #642000:   Batch Loss = 9.919218, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.299793243408203, Accuracy = 0.799878716468811
Training iter #644000:   Batch Loss = 10.210620, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.246769905090332, Accuracy = 0.7986658811569214
Training iter #646000:   Batch Loss = 9.551717, Accuracy = 0.948586106300354
PERFORMANCE ON TEST SET: Batch Loss = 12.86555290222168, Accuracy = 0.8089751601219177
Training iter #648000:   Batch Loss = 9.714214, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.863189697265625, Accuracy = 0.7944208383560181
Training iter #650000:   Batch Loss = 9.535829, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.774320602416992, Accuracy = 0.805336594581604
Training iter #652000:   Batch Loss = 9.545730, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.916886329650879, Accuracy = 0.7962401509284973
Training iter #654000:   Batch Loss = 11.205469, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 14.06139087677002, Accuracy = 0.8010915517807007
Training iter #656000:   Batch Loss = 10.918541, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.660962104797363, Accuracy = 0.7816858887672424
Training iter #658000:   Batch Loss = 11.089757, Accuracy = 0.9275000095367432
PERFORMANCE ON TEST SET: Batch Loss = 13.291543006896973, Accuracy = 0.7877501249313354
Training iter #660000:   Batch Loss = 10.437333, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.242912292480469, Accuracy = 0.7865372896194458
Training iter #662000:   Batch Loss = 9.948502, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.250632286071777, Accuracy = 0.7798665761947632
Training iter #664000:   Batch Loss = 10.741715, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 13.891461372375488, Accuracy = 0.7738022804260254
Training iter #666000:   Batch Loss = 11.104359, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 13.642467498779297, Accuracy = 0.7986658811569214
Training iter #668000:   Batch Loss = 11.366592, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 14.04035472869873, Accuracy = 0.8035172820091248
Training iter #670000:   Batch Loss = 11.034323, Accuracy = 0.9275000095367432
PERFORMANCE ON TEST SET: Batch Loss = 13.594841003417969, Accuracy = 0.7877501249313354
Training iter #672000:   Batch Loss = 11.488028, Accuracy = 0.9225000143051147
PERFORMANCE ON TEST SET: Batch Loss = 13.88301944732666, Accuracy = 0.7841115593910217
Training iter #674000:   Batch Loss = 11.324343, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 13.653204917907715, Accuracy = 0.7828987240791321
Training iter #676000:   Batch Loss = 11.050632, Accuracy = 0.9325000047683716
PERFORMANCE ON TEST SET: Batch Loss = 13.319765090942383, Accuracy = 0.797452986240387
Training iter #678000:   Batch Loss = 10.428022, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 13.304147720336914, Accuracy = 0.7877501249313354
Training iter #680000:   Batch Loss = 10.234985, Accuracy = 0.9717223644256592
PERFORMANCE ON TEST SET: Batch Loss = 13.041547775268555, Accuracy = 0.7889630198478699
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-1700
Training iter #682000:   Batch Loss = 9.836582, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.204704284667969, Accuracy = 0.7786537408828735
Training iter #684000:   Batch Loss = 10.508991, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.200814247131348, Accuracy = 0.7816858887672424
Training iter #686000:   Batch Loss = 9.934288, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.01840877532959, Accuracy = 0.7938144207000732
Training iter #688000:   Batch Loss = 9.945334, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 13.19999885559082, Accuracy = 0.780472993850708
Training iter #690000:   Batch Loss = 9.941242, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.840963363647461, Accuracy = 0.791388750076294
Training iter #692000:   Batch Loss = 9.883086, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.924302101135254, Accuracy = 0.7822923064231873
Training iter #694000:   Batch Loss = 9.477765, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 12.934548377990723, Accuracy = 0.7865372896194458
Training iter #696000:   Batch Loss = 9.453416, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.799838066101074, Accuracy = 0.7895694375038147
Training iter #698000:   Batch Loss = 9.805996, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.649053573608398, Accuracy = 0.7986658811569214
Training iter #700000:   Batch Loss = 9.656670, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 12.710272789001465, Accuracy = 0.7992722988128662
Training iter #702000:   Batch Loss = 11.064079, Accuracy = 0.925000011920929
PERFORMANCE ON TEST SET: Batch Loss = 14.012651443481445, Accuracy = 0.7956337332725525
Training iter #704000:   Batch Loss = 10.665504, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 13.896954536437988, Accuracy = 0.7756215929985046
Training iter #706000:   Batch Loss = 10.248416, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.395394325256348, Accuracy = 0.8041236996650696
Training iter #708000:   Batch Loss = 9.991804, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.268087387084961, Accuracy = 0.7956337332725525
Training iter #710000:   Batch Loss = 9.921565, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.753662109375, Accuracy = 0.7853244543075562
Training iter #712000:   Batch Loss = 10.677344, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 14.063947677612305, Accuracy = 0.7798665761947632
Training iter #714000:   Batch Loss = 10.742910, Accuracy = 0.9511567950248718
PERFORMANCE ON TEST SET: Batch Loss = 13.788795471191406, Accuracy = 0.7828987240791321
Training iter #716000:   Batch Loss = 10.988036, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.271568298339844, Accuracy = 0.8023044466972351
Training iter #718000:   Batch Loss = 10.074041, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.47165584564209, Accuracy = 0.7786537408828735
Training iter #720000:   Batch Loss = 10.615096, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 14.064218521118164, Accuracy = 0.788356602191925
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-1800
Training iter #722000:   Batch Loss = 11.277876, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 14.180132865905762, Accuracy = 0.7932080030441284
Training iter #724000:   Batch Loss = 11.017928, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.052603721618652, Accuracy = 0.7877501249313354
Training iter #726000:   Batch Loss = 11.257095, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.603144645690918, Accuracy = 0.8016979694366455
Training iter #728000:   Batch Loss = 10.681750, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.702170372009277, Accuracy = 0.7938144207000732
Training iter #730000:   Batch Loss = 10.796997, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 13.863678932189941, Accuracy = 0.7768344283103943
Training iter #732000:   Batch Loss = 10.048269, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.648331642150879, Accuracy = 0.788356602191925
Training iter #734000:   Batch Loss = 10.412486, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 13.679889678955078, Accuracy = 0.7871437072753906
Training iter #736000:   Batch Loss = 10.110128, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.4024019241333, Accuracy = 0.788356602191925
Training iter #738000:   Batch Loss = 10.483781, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 13.544096946716309, Accuracy = 0.7816858887672424
Training iter #740000:   Batch Loss = 10.362397, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.493926048278809, Accuracy = 0.8095815777778625
Training iter #742000:   Batch Loss = 10.608001, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 13.424663543701172, Accuracy = 0.7950273156166077
Training iter #744000:   Batch Loss = 10.103656, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 13.40424919128418, Accuracy = 0.785930871963501
Training iter #746000:   Batch Loss = 10.415480, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.236903190612793, Accuracy = 0.7986658811569214
Training iter #748000:   Batch Loss = 10.611006, Accuracy = 0.922879159450531
PERFORMANCE ON TEST SET: Batch Loss = 13.487405776977539, Accuracy = 0.788356602191925
Training iter #750000:   Batch Loss = 10.675988, Accuracy = 0.9225000143051147
PERFORMANCE ON TEST SET: Batch Loss = 13.214325904846191, Accuracy = 0.7926015853881836
Training iter #752000:   Batch Loss = 10.392840, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.237943649291992, Accuracy = 0.7944208383560181
Training iter #754000:   Batch Loss = 10.351733, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.183889389038086, Accuracy = 0.7871437072753906
Training iter #756000:   Batch Loss = 10.632536, Accuracy = 0.9275000095367432
PERFORMANCE ON TEST SET: Batch Loss = 12.959613800048828, Accuracy = 0.8077622652053833
Training iter #758000:   Batch Loss = 9.990762, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.737196922302246, Accuracy = 0.7756215929985046
Training iter #760000:   Batch Loss = 10.695017, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 13.302496910095215, Accuracy = 0.8077622652053833
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-1900
Training iter #762000:   Batch Loss = 10.294230, Accuracy = 0.9325000047683716
PERFORMANCE ON TEST SET: Batch Loss = 13.256628036499023, Accuracy = 0.7865372896194458
Training iter #764000:   Batch Loss = 9.647584, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.2688627243042, Accuracy = 0.7944208383560181
Training iter #766000:   Batch Loss = 10.224538, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 13.357515335083008, Accuracy = 0.7816858887672424
Training iter #768000:   Batch Loss = 10.003036, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.088253021240234, Accuracy = 0.7962401509284973
Training iter #770000:   Batch Loss = 9.693645, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.180408477783203, Accuracy = 0.7926015853881836
Training iter #772000:   Batch Loss = 9.465020, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.197502136230469, Accuracy = 0.7901758551597595
Training iter #774000:   Batch Loss = 9.768476, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.914867401123047, Accuracy = 0.8016979694366455
Training iter #776000:   Batch Loss = 9.729177, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 13.18604850769043, Accuracy = 0.7919951677322388
Training iter #778000:   Batch Loss = 10.762218, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.960217475891113, Accuracy = 0.7962401509284973
Training iter #780000:   Batch Loss = 10.242646, Accuracy = 0.9325000047683716
PERFORMANCE ON TEST SET: Batch Loss = 13.215357780456543, Accuracy = 0.7938144207000732
Training iter #782000:   Batch Loss = 9.979982, Accuracy = 0.9383033514022827
PERFORMANCE ON TEST SET: Batch Loss = 13.049854278564453, Accuracy = 0.805336594581604
Training iter #784000:   Batch Loss = 10.116246, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 13.594622611999512, Accuracy = 0.7798665761947632
Training iter #786000:   Batch Loss = 9.730282, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.248100280761719, Accuracy = 0.7962401509284973
Training iter #788000:   Batch Loss = 9.767864, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.148359298706055, Accuracy = 0.7938144207000732
Training iter #790000:   Batch Loss = 9.730302, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.142438888549805, Accuracy = 0.7768344283103943
Training iter #792000:   Batch Loss = 9.784040, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.898475646972656, Accuracy = 0.8047301173210144
Training iter #794000:   Batch Loss = 9.428679, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.969524383544922, Accuracy = 0.788356602191925
Training iter #796000:   Batch Loss = 9.407485, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.032197952270508, Accuracy = 0.7762280106544495
Training iter #798000:   Batch Loss = 9.532821, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.975600242614746, Accuracy = 0.7919951677322388
Training iter #800000:   Batch Loss = 9.599248, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.959929466247559, Accuracy = 0.7847180366516113
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-2000
Training iter #802000:   Batch Loss = 9.678196, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.857748031616211, Accuracy = 0.8010915517807007
Training iter #804000:   Batch Loss = 9.964602, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.077825546264648, Accuracy = 0.7816858887672424
Training iter #806000:   Batch Loss = 9.697359, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.01223087310791, Accuracy = 0.797452986240387
Training iter #808000:   Batch Loss = 9.915763, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.382076263427734, Accuracy = 0.7992722988128662
Training iter #810000:   Batch Loss = 10.883794, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 13.68813705444336, Accuracy = 0.8010915517807007
Training iter #812000:   Batch Loss = 10.663149, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 14.007672309875488, Accuracy = 0.7610673308372498
Training iter #814000:   Batch Loss = 10.336460, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.551186561584473, Accuracy = 0.7889630198478699
Training iter #816000:   Batch Loss = 9.995340, Accuracy = 0.9614396095275879
PERFORMANCE ON TEST SET: Batch Loss = 13.439997673034668, Accuracy = 0.7907822728157043
Training iter #818000:   Batch Loss = 9.778081, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.188738822937012, Accuracy = 0.7938144207000732
Training iter #820000:   Batch Loss = 10.001734, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 13.080327987670898, Accuracy = 0.7992722988128662
Training iter #822000:   Batch Loss = 9.495103, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.981225967407227, Accuracy = 0.7853244543075562
Training iter #824000:   Batch Loss = 10.983079, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 14.24632453918457, Accuracy = 0.785930871963501
Training iter #826000:   Batch Loss = 11.494274, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 14.082626342773438, Accuracy = 0.8089751601219177
Training iter #828000:   Batch Loss = 11.234327, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 13.918550491333008, Accuracy = 0.7828987240791321
Training iter #830000:   Batch Loss = 11.533316, Accuracy = 0.925000011920929
PERFORMANCE ON TEST SET: Batch Loss = 13.650699615478516, Accuracy = 0.7950273156166077
Training iter #832000:   Batch Loss = 11.182602, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 13.686766624450684, Accuracy = 0.7962401509284973
Training iter #834000:   Batch Loss = 10.778640, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 13.504477500915527, Accuracy = 0.7901758551597595
Training iter #836000:   Batch Loss = 10.740246, Accuracy = 0.9150000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.361270904541016, Accuracy = 0.7907822728157043
Training iter #838000:   Batch Loss = 10.267216, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.489320755004883, Accuracy = 0.7889630198478699
Training iter #840000:   Batch Loss = 10.907182, Accuracy = 0.9275000095367432
PERFORMANCE ON TEST SET: Batch Loss = 13.492342948913574, Accuracy = 0.7841115593910217
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-2100
Training iter #842000:   Batch Loss = 10.768242, Accuracy = 0.9275000095367432
PERFORMANCE ON TEST SET: Batch Loss = 13.397918701171875, Accuracy = 0.8041236996650696
Training iter #844000:   Batch Loss = 10.561476, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 13.147059440612793, Accuracy = 0.797452986240387
Training iter #846000:   Batch Loss = 10.321626, Accuracy = 0.9125000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.222816467285156, Accuracy = 0.7841115593910217
Training iter #848000:   Batch Loss = 10.524062, Accuracy = 0.9275000095367432
PERFORMANCE ON TEST SET: Batch Loss = 13.045825004577637, Accuracy = 0.7774408459663391
Training iter #850000:   Batch Loss = 10.613056, Accuracy = 0.9511567950248718
PERFORMANCE ON TEST SET: Batch Loss = 12.921943664550781, Accuracy = 0.791388750076294
Training iter #852000:   Batch Loss = 10.188866, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.064796447753906, Accuracy = 0.8059430122375488
Training iter #854000:   Batch Loss = 9.892402, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.956476211547852, Accuracy = 0.7919951677322388
Training iter #856000:   Batch Loss = 10.616118, Accuracy = 0.9150000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.06968879699707, Accuracy = 0.7968465685844421
Training iter #858000:   Batch Loss = 10.275845, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 12.984794616699219, Accuracy = 0.7853244543075562
Training iter #860000:   Batch Loss = 11.217204, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 14.006563186645508, Accuracy = 0.8095815777778625
Training iter #862000:   Batch Loss = 10.807251, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.752811431884766, Accuracy = 0.797452986240387
Training iter #864000:   Batch Loss = 10.425661, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 13.470338821411133, Accuracy = 0.8035172820091248
Training iter #866000:   Batch Loss = 10.451616, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 13.099726676940918, Accuracy = 0.8023044466972351
Training iter #868000:   Batch Loss = 10.171217, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.15182876586914, Accuracy = 0.7932080030441284
Training iter #870000:   Batch Loss = 10.040594, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.029731750488281, Accuracy = 0.8120072484016418
Training iter #872000:   Batch Loss = 9.972345, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.045721054077148, Accuracy = 0.8083686828613281
Training iter #874000:   Batch Loss = 9.805197, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.921541213989258, Accuracy = 0.8010915517807007
Training iter #876000:   Batch Loss = 10.547562, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 14.115059852600098, Accuracy = 0.785930871963501
Training iter #878000:   Batch Loss = 10.215259, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.221973419189453, Accuracy = 0.7950273156166077
Training iter #880000:   Batch Loss = 10.946822, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 13.67356014251709, Accuracy = 0.8071558475494385
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-2200
Training iter #882000:   Batch Loss = 11.443237, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 14.624377250671387, Accuracy = 0.7853244543075562
Training iter #884000:   Batch Loss = 11.264591, Accuracy = 0.9460154175758362
PERFORMANCE ON TEST SET: Batch Loss = 13.986188888549805, Accuracy = 0.7871437072753906
Training iter #886000:   Batch Loss = 11.143423, Accuracy = 0.9275000095367432
PERFORMANCE ON TEST SET: Batch Loss = 13.90451431274414, Accuracy = 0.7719830274581909
Training iter #888000:   Batch Loss = 10.804857, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.696183204650879, Accuracy = 0.7901758551597595
Training iter #890000:   Batch Loss = 10.466317, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.544595718383789, Accuracy = 0.7865372896194458
Training iter #892000:   Batch Loss = 10.478264, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.4129638671875, Accuracy = 0.7962401509284973
Training iter #894000:   Batch Loss = 10.312556, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.616325378417969, Accuracy = 0.7647058963775635
Training iter #896000:   Batch Loss = 10.696351, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 14.151315689086914, Accuracy = 0.780472993850708
Training iter #898000:   Batch Loss = 11.043315, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 14.111924171447754, Accuracy = 0.788356602191925
Training iter #900000:   Batch Loss = 10.714483, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 13.749481201171875, Accuracy = 0.7871437072753906
Training iter #902000:   Batch Loss = 10.887699, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 13.371492385864258, Accuracy = 0.799878716468811
Training iter #904000:   Batch Loss = 10.921083, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.598175048828125, Accuracy = 0.7841115593910217
Training iter #906000:   Batch Loss = 10.444702, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.60378646850586, Accuracy = 0.791388750076294
Training iter #908000:   Batch Loss = 10.631905, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 13.6102294921875, Accuracy = 0.780472993850708
Training iter #910000:   Batch Loss = 10.857595, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 13.22496223449707, Accuracy = 0.8095815777778625
Training iter #912000:   Batch Loss = 10.371201, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 13.441926956176758, Accuracy = 0.785930871963501
Training iter #914000:   Batch Loss = 10.327482, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.36330509185791, Accuracy = 0.805336594581604
Training iter #916000:   Batch Loss = 10.074999, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.295031547546387, Accuracy = 0.7901758551597595
Training iter #918000:   Batch Loss = 10.629098, Accuracy = 0.9203084707260132
PERFORMANCE ON TEST SET: Batch Loss = 13.315113067626953, Accuracy = 0.8035172820091248
Training iter #920000:   Batch Loss = 10.195974, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.281929016113281, Accuracy = 0.7907822728157043
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-2300
Training iter #922000:   Batch Loss = 10.576664, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.91650676727295, Accuracy = 0.7944208383560181
Training iter #924000:   Batch Loss = 10.713183, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 13.710103034973145, Accuracy = 0.8059430122375488
Training iter #926000:   Batch Loss = 10.091664, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.377178192138672, Accuracy = 0.8047301173210144
Training iter #928000:   Batch Loss = 10.606112, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.338907241821289, Accuracy = 0.7944208383560181
Training iter #930000:   Batch Loss = 10.280519, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.225817680358887, Accuracy = 0.8047301173210144
Training iter #932000:   Batch Loss = 10.264354, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 13.200016021728516, Accuracy = 0.7877501249313354
Training iter #934000:   Batch Loss = 9.638253, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.166280746459961, Accuracy = 0.8047301173210144
Training iter #936000:   Batch Loss = 9.761791, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.021903991699219, Accuracy = 0.7986658811569214
Training iter #938000:   Batch Loss = 9.725014, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.110835075378418, Accuracy = 0.7962401509284973
Training iter #940000:   Batch Loss = 9.628331, Accuracy = 0.9424999952316284
PERFORMANCE ON TEST SET: Batch Loss = 13.264455795288086, Accuracy = 0.7901758551597595
Training iter #942000:   Batch Loss = 9.753806, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.106128692626953, Accuracy = 0.7841115593910217
Training iter #944000:   Batch Loss = 9.648631, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.245999336242676, Accuracy = 0.7871437072753906
Training iter #946000:   Batch Loss = 9.468990, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.90268325805664, Accuracy = 0.7992722988128662
Training iter #948000:   Batch Loss = 9.253301, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.003704071044922, Accuracy = 0.7944208383560181
Training iter #950000:   Batch Loss = 9.360140, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.908794403076172, Accuracy = 0.8120072484016418
Training iter #952000:   Batch Loss = 9.259853, Accuracy = 0.9640102982521057
PERFORMANCE ON TEST SET: Batch Loss = 13.039002418518066, Accuracy = 0.7750151753425598
Training iter #954000:   Batch Loss = 9.507116, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.361539840698242, Accuracy = 0.7962401509284973
Training iter #956000:   Batch Loss = 9.737224, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 12.944385528564453, Accuracy = 0.7895694375038147
Training iter #958000:   Batch Loss = 9.111700, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.839071273803711, Accuracy = 0.7932080030441284
Training iter #960000:   Batch Loss = 9.259352, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.1016206741333, Accuracy = 0.7907822728157043
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-2400
Training iter #962000:   Batch Loss = 9.424589, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.929948806762695, Accuracy = 0.7992722988128662
Training iter #964000:   Batch Loss = 9.203325, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.811168670654297, Accuracy = 0.8089751601219177
Training iter #966000:   Batch Loss = 9.516489, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.74742317199707, Accuracy = 0.8186779618263245
Training iter #968000:   Batch Loss = 9.416164, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.920083999633789, Accuracy = 0.791388750076294
Training iter #970000:   Batch Loss = 8.595841, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.849376678466797, Accuracy = 0.7889630198478699
Training iter #972000:   Batch Loss = 9.070374, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.724400520324707, Accuracy = 0.7950273156166077
Training iter #974000:   Batch Loss = 9.381242, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.884212493896484, Accuracy = 0.799878716468811
Training iter #976000:   Batch Loss = 9.853488, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.250431060791016, Accuracy = 0.7877501249313354
Training iter #978000:   Batch Loss = 9.641730, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.52098560333252, Accuracy = 0.7841115593910217
Training iter #980000:   Batch Loss = 9.279784, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.131120681762695, Accuracy = 0.7968465685844421
Training iter #982000:   Batch Loss = 9.454861, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.233259201049805, Accuracy = 0.7932080030441284
Training iter #984000:   Batch Loss = 9.822256, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.840679168701172, Accuracy = 0.8095815777778625
Training iter #986000:   Batch Loss = 9.859495, Accuracy = 0.9614396095275879
PERFORMANCE ON TEST SET: Batch Loss = 13.057812690734863, Accuracy = 0.788356602191925
Training iter #988000:   Batch Loss = 9.961469, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 13.04307746887207, Accuracy = 0.8035172820091248
Training iter #990000:   Batch Loss = 9.056499, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.025213241577148, Accuracy = 0.8004851341247559
Training iter #992000:   Batch Loss = 9.112966, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.889870643615723, Accuracy = 0.8071558475494385
Training iter #994000:   Batch Loss = 9.485855, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.26870346069336, Accuracy = 0.7956337332725525
Training iter #996000:   Batch Loss = 9.810322, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.074871063232422, Accuracy = 0.7865372896194458
Training iter #998000:   Batch Loss = 9.603422, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.81761360168457, Accuracy = 0.8023044466972351
Training iter #1000000:   Batch Loss = 9.144349, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.998303413391113, Accuracy = 0.799878716468811
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-2500
Training iter #1002000:   Batch Loss = 8.801450, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.806968688964844, Accuracy = 0.8023044466972351
Training iter #1004000:   Batch Loss = 9.200429, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.786161422729492, Accuracy = 0.8016979694366455
Training iter #1006000:   Batch Loss = 9.128145, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.846709251403809, Accuracy = 0.8101879954338074
Training iter #1008000:   Batch Loss = 9.366385, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.0431489944458, Accuracy = 0.7841115593910217
Training iter #1010000:   Batch Loss = 8.906219, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.030136108398438, Accuracy = 0.8029108643531799
Training iter #1012000:   Batch Loss = 9.470756, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.006573677062988, Accuracy = 0.8016979694366455
Training iter #1014000:   Batch Loss = 9.276993, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.082979202270508, Accuracy = 0.8077622652053833
Training iter #1016000:   Batch Loss = 9.724257, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.48737907409668, Accuracy = 0.8047301173210144
Training iter #1018000:   Batch Loss = 9.996622, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 14.218826293945312, Accuracy = 0.7919951677322388
Training iter #1020000:   Batch Loss = 10.054086, Accuracy = 0.9640102982521057
PERFORMANCE ON TEST SET: Batch Loss = 13.735546112060547, Accuracy = 0.8174651265144348
Training iter #1022000:   Batch Loss = 9.840223, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.827302932739258, Accuracy = 0.7919951677322388
Training iter #1024000:   Batch Loss = 9.936096, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.644081115722656, Accuracy = 0.7986658811569214
Training iter #1026000:   Batch Loss = 9.709852, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.583686828613281, Accuracy = 0.7901758551597595
Training iter #1028000:   Batch Loss = 10.160554, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.785065650939941, Accuracy = 0.7865372896194458
Training iter #1030000:   Batch Loss = 10.004039, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.624611854553223, Accuracy = 0.780472993850708
Training iter #1032000:   Batch Loss = 9.668478, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.415103912353516, Accuracy = 0.799878716468811
Training iter #1034000:   Batch Loss = 9.165326, Accuracy = 0.9825000166893005
PERFORMANCE ON TEST SET: Batch Loss = 13.256820678710938, Accuracy = 0.7810794711112976
Training iter #1036000:   Batch Loss = 9.329723, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.867057800292969, Accuracy = 0.8132201433181763
Training iter #1038000:   Batch Loss = 9.827481, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.100728988647461, Accuracy = 0.7986658811569214
Training iter #1040000:   Batch Loss = 9.615664, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 13.13367748260498, Accuracy = 0.791388750076294
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-2600
Training iter #1042000:   Batch Loss = 9.446087, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.101519584655762, Accuracy = 0.7950273156166077
Training iter #1044000:   Batch Loss = 9.565331, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.145675659179688, Accuracy = 0.7901758551597595
Training iter #1046000:   Batch Loss = 9.383625, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.83892822265625, Accuracy = 0.805336594581604
Training iter #1048000:   Batch Loss = 9.448573, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.12266731262207, Accuracy = 0.8004851341247559
Training iter #1050000:   Batch Loss = 9.245907, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.081914901733398, Accuracy = 0.788356602191925
Training iter #1052000:   Batch Loss = 9.611892, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 13.027251243591309, Accuracy = 0.797452986240387
Training iter #1054000:   Batch Loss = 9.440730, Accuracy = 0.9537274837493896
PERFORMANCE ON TEST SET: Batch Loss = 13.00415325164795, Accuracy = 0.7841115593910217
Training iter #1056000:   Batch Loss = 9.531543, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.80236530303955, Accuracy = 0.8059430122375488
Training iter #1058000:   Batch Loss = 9.480520, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.845552444458008, Accuracy = 0.7938144207000732
Training iter #1060000:   Batch Loss = 9.275528, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 12.722589492797852, Accuracy = 0.8065494298934937
Training iter #1062000:   Batch Loss = 9.594511, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 12.777288436889648, Accuracy = 0.7938144207000732
Training iter #1064000:   Batch Loss = 9.199267, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.804350852966309, Accuracy = 0.7865372896194458
Training iter #1066000:   Batch Loss = 9.515500, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.407929420471191, Accuracy = 0.8120072484016418
Training iter #1068000:   Batch Loss = 9.181958, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.075886726379395, Accuracy = 0.7901758551597595
Training iter #1070000:   Batch Loss = 9.187599, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.89698600769043, Accuracy = 0.8010915517807007
Training iter #1072000:   Batch Loss = 9.109201, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.772968292236328, Accuracy = 0.7932080030441284
Training iter #1074000:   Batch Loss = 8.780016, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.526199340820312, Accuracy = 0.811400830745697
Training iter #1076000:   Batch Loss = 8.884667, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.866804122924805, Accuracy = 0.7774408459663391
Training iter #1078000:   Batch Loss = 8.991520, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.534082412719727, Accuracy = 0.8023044466972351
Training iter #1080000:   Batch Loss = 8.864632, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.626626014709473, Accuracy = 0.8174651265144348
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-2700
Training iter #1082000:   Batch Loss = 8.756448, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.437727928161621, Accuracy = 0.8192844390869141
Training iter #1084000:   Batch Loss = 9.153173, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.955141067504883, Accuracy = 0.8029108643531799
Training iter #1086000:   Batch Loss = 8.347040, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.928277015686035, Accuracy = 0.8029108643531799
Training iter #1088000:   Batch Loss = 9.168958, Accuracy = 0.9665809869766235
PERFORMANCE ON TEST SET: Batch Loss = 13.087247848510742, Accuracy = 0.7865372896194458
Training iter #1090000:   Batch Loss = 8.909681, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.724174499511719, Accuracy = 0.8029108643531799
Training iter #1092000:   Batch Loss = 9.273788, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.987363815307617, Accuracy = 0.7919951677322388
Training iter #1094000:   Batch Loss = 8.964613, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.118918418884277, Accuracy = 0.8095815777778625
Training iter #1096000:   Batch Loss = 9.835070, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.225093841552734, Accuracy = 0.8095815777778625
Training iter #1098000:   Batch Loss = 9.429176, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.283209800720215, Accuracy = 0.7944208383560181
Training iter #1100000:   Batch Loss = 10.206059, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.40487003326416, Accuracy = 0.8150393962860107
Training iter #1102000:   Batch Loss = 9.851507, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.605551719665527, Accuracy = 0.785930871963501
Training iter #1104000:   Batch Loss = 9.757689, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.13451862335205, Accuracy = 0.8065494298934937
Training iter #1106000:   Batch Loss = 9.600843, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.338253021240234, Accuracy = 0.8083686828613281
Training iter #1108000:   Batch Loss = 9.590869, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.62839412689209, Accuracy = 0.7932080030441284
Training iter #1110000:   Batch Loss = 9.780244, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.231590270996094, Accuracy = 0.8035172820091248
Training iter #1112000:   Batch Loss = 9.443300, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.02369213104248, Accuracy = 0.7986658811569214
Training iter #1114000:   Batch Loss = 9.671079, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.31578254699707, Accuracy = 0.8010915517807007
Training iter #1116000:   Batch Loss = 9.089335, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.134397506713867, Accuracy = 0.797452986240387
Training iter #1118000:   Batch Loss = 8.973162, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.885034561157227, Accuracy = 0.8059430122375488
Training iter #1120000:   Batch Loss = 8.990026, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.027623176574707, Accuracy = 0.7907822728157043
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-2800
Training iter #1122000:   Batch Loss = 9.021986, Accuracy = 0.9640102982521057
PERFORMANCE ON TEST SET: Batch Loss = 12.893940925598145, Accuracy = 0.7986658811569214
Training iter #1124000:   Batch Loss = 8.714462, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.898078918457031, Accuracy = 0.7950273156166077
Training iter #1126000:   Batch Loss = 8.883806, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 12.756159782409668, Accuracy = 0.799878716468811
Training iter #1128000:   Batch Loss = 8.777685, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.653080940246582, Accuracy = 0.8089751601219177
Training iter #1130000:   Batch Loss = 8.902330, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.861352920532227, Accuracy = 0.8004851341247559
Training iter #1132000:   Batch Loss = 8.974243, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.624359130859375, Accuracy = 0.8071558475494385
Training iter #1134000:   Batch Loss = 9.187700, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 12.735794067382812, Accuracy = 0.8047301173210144
Training iter #1136000:   Batch Loss = 8.569446, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.619369506835938, Accuracy = 0.8126137256622314
Training iter #1138000:   Batch Loss = 8.535126, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.965003967285156, Accuracy = 0.7907822728157043
Training iter #1140000:   Batch Loss = 8.512168, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.622018814086914, Accuracy = 0.8077622652053833
Training iter #1142000:   Batch Loss = 8.742096, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.12381362915039, Accuracy = 0.7968465685844421
Training iter #1144000:   Batch Loss = 8.368848, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 12.644754409790039, Accuracy = 0.7992722988128662
Training iter #1146000:   Batch Loss = 8.550318, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.67352294921875, Accuracy = 0.8041236996650696
Training iter #1148000:   Batch Loss = 8.656666, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 12.661901473999023, Accuracy = 0.8089751601219177
Training iter #1150000:   Batch Loss = 8.611662, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.642983436584473, Accuracy = 0.8059430122375488
Training iter #1152000:   Batch Loss = 8.515397, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 12.69769287109375, Accuracy = 0.8041236996650696
Training iter #1154000:   Batch Loss = 8.255234, Accuracy = 0.9825000166893005
PERFORMANCE ON TEST SET: Batch Loss = 12.525785446166992, Accuracy = 0.8144329786300659
Training iter #1156000:   Batch Loss = 8.611390, Accuracy = 0.9640102982521057
PERFORMANCE ON TEST SET: Batch Loss = 12.615422248840332, Accuracy = 0.8047301173210144
Training iter #1158000:   Batch Loss = 8.292591, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 12.426231384277344, Accuracy = 0.8095815777778625
Training iter #1160000:   Batch Loss = 8.351807, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.584803581237793, Accuracy = 0.8120072484016418
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-2900
Training iter #1162000:   Batch Loss = 8.405123, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.698216438293457, Accuracy = 0.8047301173210144
Training iter #1164000:   Batch Loss = 8.358568, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.737810134887695, Accuracy = 0.8089751601219177
Training iter #1166000:   Batch Loss = 8.732382, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.827354431152344, Accuracy = 0.8150393962860107
Training iter #1168000:   Batch Loss = 8.767197, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.666646003723145, Accuracy = 0.7980594038963318
Training iter #1170000:   Batch Loss = 8.680834, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.59481430053711, Accuracy = 0.811400830745697
Training iter #1172000:   Batch Loss = 9.427588, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.471639633178711, Accuracy = 0.7810794711112976
Training iter #1174000:   Batch Loss = 8.973980, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.731128692626953, Accuracy = 0.8174651265144348
Training iter #1176000:   Batch Loss = 9.176774, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 12.816839218139648, Accuracy = 0.7895694375038147
Training iter #1178000:   Batch Loss = 8.855312, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.603482246398926, Accuracy = 0.8059430122375488
Training iter #1180000:   Batch Loss = 8.332119, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.798601150512695, Accuracy = 0.7992722988128662
Training iter #1182000:   Batch Loss = 8.704452, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 12.898514747619629, Accuracy = 0.8016979694366455
Training iter #1184000:   Batch Loss = 8.775236, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.7635498046875, Accuracy = 0.8059430122375488
Training iter #1186000:   Batch Loss = 8.060008, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.973016738891602, Accuracy = 0.7847180366516113
Training iter #1188000:   Batch Loss = 8.536925, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.77267837524414, Accuracy = 0.8023044466972351
Training iter #1190000:   Batch Loss = 8.027706, Accuracy = 0.9691516757011414
PERFORMANCE ON TEST SET: Batch Loss = 12.928215026855469, Accuracy = 0.7938144207000732
Training iter #1192000:   Batch Loss = 8.660014, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.520722389221191, Accuracy = 0.8107944130897522
Training iter #1194000:   Batch Loss = 9.087996, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.633842468261719, Accuracy = 0.805336594581604
Training iter #1196000:   Batch Loss = 9.512006, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.919536590576172, Accuracy = 0.8023044466972351
Training iter #1198000:   Batch Loss = 10.613008, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 14.20999813079834, Accuracy = 0.7707701921463013
Training iter #1200000:   Batch Loss = 9.864134, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.782225608825684, Accuracy = 0.8095815777778625
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-3000
Training iter #1202000:   Batch Loss = 9.366693, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.948387145996094, Accuracy = 0.774408757686615
Training iter #1204000:   Batch Loss = 9.835797, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.353246688842773, Accuracy = 0.8035172820091248
Training iter #1206000:   Batch Loss = 9.509777, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.432601928710938, Accuracy = 0.799878716468811
Training iter #1208000:   Batch Loss = 9.196796, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.546859741210938, Accuracy = 0.7877501249313354
Training iter #1210000:   Batch Loss = 9.524298, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.353711128234863, Accuracy = 0.7877501249313354
Training iter #1212000:   Batch Loss = 9.434280, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.208600997924805, Accuracy = 0.8029108643531799
Training iter #1214000:   Batch Loss = 9.040583, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.136805534362793, Accuracy = 0.7889630198478699
Training iter #1216000:   Batch Loss = 9.292461, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.1282958984375, Accuracy = 0.7962401509284973
Training iter #1218000:   Batch Loss = 9.027662, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.153450012207031, Accuracy = 0.791388750076294
Training iter #1220000:   Batch Loss = 9.081538, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.060134887695312, Accuracy = 0.805336594581604
Training iter #1222000:   Batch Loss = 9.638094, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.077512741088867, Accuracy = 0.8107944130897522
Training iter #1224000:   Batch Loss = 9.861781, Accuracy = 0.9691516757011414
PERFORMANCE ON TEST SET: Batch Loss = 13.29548168182373, Accuracy = 0.7956337332725525
Training iter #1226000:   Batch Loss = 9.498842, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.240096092224121, Accuracy = 0.7828987240791321
Training iter #1228000:   Batch Loss = 9.111408, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.903495788574219, Accuracy = 0.797452986240387
Training iter #1230000:   Batch Loss = 8.921287, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.699716567993164, Accuracy = 0.8162522912025452
Training iter #1232000:   Batch Loss = 9.095173, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 12.843013763427734, Accuracy = 0.7992722988128662
Training iter #1234000:   Batch Loss = 8.851532, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 12.985950469970703, Accuracy = 0.797452986240387
Training iter #1236000:   Batch Loss = 9.276817, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.984697341918945, Accuracy = 0.7956337332725525
Training iter #1238000:   Batch Loss = 8.898924, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.79568862915039, Accuracy = 0.8101879954338074
Training iter #1240000:   Batch Loss = 9.476323, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.289125442504883, Accuracy = 0.7828987240791321
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-3100
Training iter #1242000:   Batch Loss = 8.863032, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 12.740799903869629, Accuracy = 0.8095815777778625
Training iter #1244000:   Batch Loss = 8.654702, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.049057006835938, Accuracy = 0.8004851341247559
Training iter #1246000:   Batch Loss = 8.660999, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 12.917346000671387, Accuracy = 0.8065494298934937
Training iter #1248000:   Batch Loss = 8.662389, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 12.858145713806152, Accuracy = 0.8004851341247559
Training iter #1250000:   Batch Loss = 8.850272, Accuracy = 0.9825000166893005
PERFORMANCE ON TEST SET: Batch Loss = 13.040289878845215, Accuracy = 0.805336594581604
Training iter #1252000:   Batch Loss = 8.857439, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.897037506103516, Accuracy = 0.8120072484016418
Training iter #1254000:   Batch Loss = 8.877308, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.78081226348877, Accuracy = 0.8083686828613281
Training iter #1256000:   Batch Loss = 9.017089, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.739492416381836, Accuracy = 0.811400830745697
Training iter #1258000:   Batch Loss = 8.797293, Accuracy = 0.9665809869766235
PERFORMANCE ON TEST SET: Batch Loss = 12.512251853942871, Accuracy = 0.8156458735466003
Training iter #1260000:   Batch Loss = 8.912127, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.618071556091309, Accuracy = 0.8083686828613281
Training iter #1262000:   Batch Loss = 8.672750, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.783348083496094, Accuracy = 0.8071558475494385
Training iter #1264000:   Batch Loss = 8.690828, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 12.530463218688965, Accuracy = 0.8065494298934937
Training iter #1266000:   Batch Loss = 8.567484, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.492324829101562, Accuracy = 0.8041236996650696
Training iter #1268000:   Batch Loss = 8.609830, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.716568946838379, Accuracy = 0.8144329786300659
Training iter #1270000:   Batch Loss = 8.163730, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 12.646470069885254, Accuracy = 0.8126137256622314
Training iter #1272000:   Batch Loss = 8.212167, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 12.569986343383789, Accuracy = 0.8211036920547485
Training iter #1274000:   Batch Loss = 8.939672, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.165913581848145, Accuracy = 0.8023044466972351
Training iter #1276000:   Batch Loss = 8.819576, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.392565727233887, Accuracy = 0.8016979694366455
Training iter #1278000:   Batch Loss = 9.650192, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.223630905151367, Accuracy = 0.8083686828613281
Training iter #1280000:   Batch Loss = 8.973816, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 12.830538749694824, Accuracy = 0.7980594038963318
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-3200
Training iter #1282000:   Batch Loss = 9.263388, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.040775299072266, Accuracy = 0.788356602191925
Training iter #1284000:   Batch Loss = 8.749696, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 12.783636093139648, Accuracy = 0.8138265609741211
Training iter #1286000:   Batch Loss = 9.354853, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.475933074951172, Accuracy = 0.8077622652053833
Training iter #1288000:   Batch Loss = 10.201056, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.773764610290527, Accuracy = 0.8016979694366455
Training iter #1290000:   Batch Loss = 10.151101, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.923186302185059, Accuracy = 0.7877501249313354
Training iter #1292000:   Batch Loss = 9.775988, Accuracy = 0.974293053150177
PERFORMANCE ON TEST SET: Batch Loss = 13.73971176147461, Accuracy = 0.811400830745697
Training iter #1294000:   Batch Loss = 9.077242, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.361213684082031, Accuracy = 0.8035172820091248
Training iter #1296000:   Batch Loss = 10.101828, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.346254348754883, Accuracy = 0.8211036920547485
Training iter #1298000:   Batch Loss = 9.531435, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.584468841552734, Accuracy = 0.7980594038963318
Training iter #1300000:   Batch Loss = 9.329332, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.307452201843262, Accuracy = 0.7986658811569214
Training iter #1302000:   Batch Loss = 9.286293, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.247884750366211, Accuracy = 0.8029108643531799
Training iter #1304000:   Batch Loss = 9.152655, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.134422302246094, Accuracy = 0.8120072484016418
Training iter #1306000:   Batch Loss = 9.793493, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.222860336303711, Accuracy = 0.8010915517807007
Training iter #1308000:   Batch Loss = 9.520782, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.115985870361328, Accuracy = 0.8083686828613281
Training iter #1310000:   Batch Loss = 9.318622, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.177650451660156, Accuracy = 0.799878716468811
Training iter #1312000:   Batch Loss = 9.741072, Accuracy = 0.9350000023841858
PERFORMANCE ON TEST SET: Batch Loss = 13.226963996887207, Accuracy = 0.7986658811569214
Training iter #1314000:   Batch Loss = 9.029562, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.043866157531738, Accuracy = 0.8059430122375488
Training iter #1316000:   Batch Loss = 9.236528, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.12803840637207, Accuracy = 0.7956337332725525
Training iter #1318000:   Batch Loss = 9.815182, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.300580024719238, Accuracy = 0.8083686828613281
Training iter #1320000:   Batch Loss = 9.220294, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.137121200561523, Accuracy = 0.8101879954338074
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-3300
Training iter #1322000:   Batch Loss = 9.657918, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.551461219787598, Accuracy = 0.7810794711112976
Training iter #1324000:   Batch Loss = 10.055990, Accuracy = 0.9399999976158142
PERFORMANCE ON TEST SET: Batch Loss = 13.127399444580078, Accuracy = 0.7956337332725525
Training iter #1326000:   Batch Loss = 10.161251, Accuracy = 0.9768637418746948
PERFORMANCE ON TEST SET: Batch Loss = 13.778618812561035, Accuracy = 0.805336594581604
Training iter #1328000:   Batch Loss = 9.643909, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.651010513305664, Accuracy = 0.8035172820091248
Training iter #1330000:   Batch Loss = 9.661602, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.343292236328125, Accuracy = 0.799878716468811
Training iter #1332000:   Batch Loss = 9.585392, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.491522789001465, Accuracy = 0.7701637148857117
Training iter #1334000:   Batch Loss = 9.501871, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.864397048950195, Accuracy = 0.8083686828613281
Training iter #1336000:   Batch Loss = 8.745308, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.060552597045898, Accuracy = 0.8016979694366455
Training iter #1338000:   Batch Loss = 9.108310, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.155956268310547, Accuracy = 0.7980594038963318
Training iter #1340000:   Batch Loss = 8.876500, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 12.837445259094238, Accuracy = 0.8089751601219177
Training iter #1342000:   Batch Loss = 8.775290, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.087505340576172, Accuracy = 0.8065494298934937
Training iter #1344000:   Batch Loss = 8.976243, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.01723861694336, Accuracy = 0.8083686828613281
Training iter #1346000:   Batch Loss = 9.287389, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.098991394042969, Accuracy = 0.7980594038963318
Training iter #1348000:   Batch Loss = 8.487241, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.148463249206543, Accuracy = 0.7986658811569214
Training iter #1350000:   Batch Loss = 8.781982, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.012716293334961, Accuracy = 0.7986658811569214
Training iter #1352000:   Batch Loss = 9.050890, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.521227836608887, Accuracy = 0.8029108643531799
Training iter #1354000:   Batch Loss = 9.506519, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 13.550882339477539, Accuracy = 0.8071558475494385
Training iter #1356000:   Batch Loss = 9.453781, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.51926040649414, Accuracy = 0.8095815777778625
Training iter #1358000:   Batch Loss = 8.967173, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.227142333984375, Accuracy = 0.8204972743988037
Training iter #1360000:   Batch Loss = 9.122699, Accuracy = 0.9717223644256592
PERFORMANCE ON TEST SET: Batch Loss = 13.276884078979492, Accuracy = 0.7932080030441284
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-3400
Training iter #1362000:   Batch Loss = 9.013140, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.536444664001465, Accuracy = 0.8083686828613281
Training iter #1364000:   Batch Loss = 9.153283, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.471437454223633, Accuracy = 0.7932080030441284
Training iter #1366000:   Batch Loss = 9.584417, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.314791679382324, Accuracy = 0.8126137256622314
Training iter #1368000:   Batch Loss = 9.173908, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.576851844787598, Accuracy = 0.8010915517807007
Training iter #1370000:   Batch Loss = 9.207748, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 13.341489791870117, Accuracy = 0.8083686828613281
Training iter #1372000:   Batch Loss = 9.428234, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.217294692993164, Accuracy = 0.8016979694366455
Training iter #1374000:   Batch Loss = 9.799246, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.81081771850586, Accuracy = 0.8120072484016418
Training iter #1376000:   Batch Loss = 10.442021, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.142683029174805, Accuracy = 0.7980594038963318
Training iter #1378000:   Batch Loss = 11.912434, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 14.739946365356445, Accuracy = 0.8010915517807007
Training iter #1380000:   Batch Loss = 12.903320, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 15.538799285888672, Accuracy = 0.7786537408828735
Training iter #1382000:   Batch Loss = 11.602745, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 14.565138816833496, Accuracy = 0.7919951677322388
Training iter #1384000:   Batch Loss = 11.481907, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 14.479986190795898, Accuracy = 0.8047301173210144
Training iter #1386000:   Batch Loss = 10.941015, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 14.396350860595703, Accuracy = 0.7968465685844421
Training iter #1388000:   Batch Loss = 10.387621, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 14.243000984191895, Accuracy = 0.7950273156166077
Training iter #1390000:   Batch Loss = 10.654118, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 14.229948997497559, Accuracy = 0.7835051417350769
Training iter #1392000:   Batch Loss = 10.459821, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 14.244537353515625, Accuracy = 0.8004851341247559
Training iter #1394000:   Batch Loss = 10.534225, Accuracy = 0.948586106300354
PERFORMANCE ON TEST SET: Batch Loss = 14.150106430053711, Accuracy = 0.8023044466972351
Training iter #1396000:   Batch Loss = 10.753677, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 14.088397026062012, Accuracy = 0.8077622652053833
Training iter #1398000:   Batch Loss = 11.956160, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 14.913628578186035, Accuracy = 0.7950273156166077
Training iter #1400000:   Batch Loss = 11.589354, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 14.767526626586914, Accuracy = 0.7835051417350769
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-3500
Training iter #1402000:   Batch Loss = 10.900697, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.295262336730957, Accuracy = 0.8089751601219177
Training iter #1404000:   Batch Loss = 11.453615, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 14.283790588378906, Accuracy = 0.8010915517807007
Training iter #1406000:   Batch Loss = 10.572989, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.255727767944336, Accuracy = 0.8016979694366455
Training iter #1408000:   Batch Loss = 10.205800, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.902715682983398, Accuracy = 0.7986658811569214
Training iter #1410000:   Batch Loss = 10.330815, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.885244369506836, Accuracy = 0.8065494298934937
Training iter #1412000:   Batch Loss = 10.447470, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 14.090511322021484, Accuracy = 0.7938144207000732
Training iter #1414000:   Batch Loss = 10.161872, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 14.00570297241211, Accuracy = 0.7907822728157043
Training iter #1416000:   Batch Loss = 10.371757, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 14.482519149780273, Accuracy = 0.7968465685844421
Training iter #1418000:   Batch Loss = 10.934424, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.081247329711914, Accuracy = 0.8047301173210144
Training iter #1420000:   Batch Loss = 10.199814, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.824040412902832, Accuracy = 0.8107944130897522
Training iter #1422000:   Batch Loss = 9.882132, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.642261505126953, Accuracy = 0.8041236996650696
Training iter #1424000:   Batch Loss = 10.163808, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 14.125652313232422, Accuracy = 0.8107944130897522
Training iter #1426000:   Batch Loss = 10.245287, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 14.053834915161133, Accuracy = 0.8083686828613281
Training iter #1428000:   Batch Loss = 11.270781, Accuracy = 0.9588689208030701
PERFORMANCE ON TEST SET: Batch Loss = 14.341314315795898, Accuracy = 0.797452986240387
Training iter #1430000:   Batch Loss = 10.883353, Accuracy = 0.9375
PERFORMANCE ON TEST SET: Batch Loss = 14.065420150756836, Accuracy = 0.8041236996650696
Training iter #1432000:   Batch Loss = 10.600605, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 14.07538890838623, Accuracy = 0.7877501249313354
Training iter #1434000:   Batch Loss = 10.776909, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.671174049377441, Accuracy = 0.8041236996650696
Training iter #1436000:   Batch Loss = 10.411049, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.886381149291992, Accuracy = 0.8016979694366455
Training iter #1438000:   Batch Loss = 9.988792, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.701122283935547, Accuracy = 0.797452986240387
Training iter #1440000:   Batch Loss = 10.396096, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.693042755126953, Accuracy = 0.7962401509284973
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-3600
Training iter #1442000:   Batch Loss = 10.142875, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.446791648864746, Accuracy = 0.8192844390869141
Training iter #1444000:   Batch Loss = 9.764669, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.397394180297852, Accuracy = 0.8071558475494385
Training iter #1446000:   Batch Loss = 10.559441, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.776871681213379, Accuracy = 0.7865372896194458
Training iter #1448000:   Batch Loss = 11.464881, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 14.969651222229004, Accuracy = 0.7980594038963318
Training iter #1450000:   Batch Loss = 10.603834, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 14.205005645751953, Accuracy = 0.797452986240387
Training iter #1452000:   Batch Loss = 9.898238, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.920866012573242, Accuracy = 0.8047301173210144
Training iter #1454000:   Batch Loss = 10.312763, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 14.003396034240723, Accuracy = 0.7932080030441284
Training iter #1456000:   Batch Loss = 9.848043, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.828805923461914, Accuracy = 0.797452986240387
Training iter #1458000:   Batch Loss = 10.040228, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.792529106140137, Accuracy = 0.8029108643531799
Training iter #1460000:   Batch Loss = 9.785477, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.78575325012207, Accuracy = 0.791388750076294
Training iter #1462000:   Batch Loss = 10.014472, Accuracy = 0.9768637418746948
PERFORMANCE ON TEST SET: Batch Loss = 13.795207977294922, Accuracy = 0.8023044466972351
Training iter #1464000:   Batch Loss = 10.273279, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 14.174908638000488, Accuracy = 0.7695572972297668
Training iter #1466000:   Batch Loss = 10.107135, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.183659553527832, Accuracy = 0.8023044466972351
Training iter #1468000:   Batch Loss = 10.671740, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.075798988342285, Accuracy = 0.7950273156166077
Training iter #1470000:   Batch Loss = 10.733822, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.998186111450195, Accuracy = 0.7956337332725525
Training iter #1472000:   Batch Loss = 12.418262, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 15.163022994995117, Accuracy = 0.791388750076294
Training iter #1474000:   Batch Loss = 11.482161, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.779512405395508, Accuracy = 0.7919951677322388
Training iter #1476000:   Batch Loss = 10.775246, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.842277526855469, Accuracy = 0.780472993850708
Training iter #1478000:   Batch Loss = 10.672361, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.59030818939209, Accuracy = 0.8004851341247559
Training iter #1480000:   Batch Loss = 10.851885, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 14.526477813720703, Accuracy = 0.7962401509284973
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-3700
Training iter #1482000:   Batch Loss = 11.174900, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 14.627326965332031, Accuracy = 0.7980594038963318
Training iter #1484000:   Batch Loss = 10.746552, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 14.972121238708496, Accuracy = 0.791388750076294
Training iter #1486000:   Batch Loss = 11.455889, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.93077278137207, Accuracy = 0.788356602191925
Training iter #1488000:   Batch Loss = 10.865417, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 14.59188461303711, Accuracy = 0.7950273156166077
Training iter #1490000:   Batch Loss = 10.866189, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.551267623901367, Accuracy = 0.7956337332725525
Training iter #1492000:   Batch Loss = 10.585958, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.533317565917969, Accuracy = 0.7841115593910217
Training iter #1494000:   Batch Loss = 10.545305, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.326379776000977, Accuracy = 0.8035172820091248
Training iter #1496000:   Batch Loss = 11.000876, Accuracy = 0.9511567950248718
PERFORMANCE ON TEST SET: Batch Loss = 14.577709197998047, Accuracy = 0.791388750076294
Training iter #1498000:   Batch Loss = 10.744528, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 14.638643264770508, Accuracy = 0.7895694375038147
Training iter #1500000:   Batch Loss = 10.600765, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 14.713191986083984, Accuracy = 0.7895694375038147
Training iter #1502000:   Batch Loss = 10.728312, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 14.511786460876465, Accuracy = 0.7810794711112976
Training iter #1504000:   Batch Loss = 10.880188, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 15.17088508605957, Accuracy = 0.7968465685844421
Training iter #1506000:   Batch Loss = 11.401779, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 15.35348129272461, Accuracy = 0.7877501249313354
Training iter #1508000:   Batch Loss = 11.390692, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 15.162961959838867, Accuracy = 0.7926015853881836
Training iter #1510000:   Batch Loss = 12.340304, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 16.287267684936523, Accuracy = 0.7568222880363464
Training iter #1512000:   Batch Loss = 12.302683, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 15.62326717376709, Accuracy = 0.7889630198478699
Training iter #1514000:   Batch Loss = 11.734115, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 15.402507781982422, Accuracy = 0.7877501249313354
Training iter #1516000:   Batch Loss = 11.595632, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 15.43861198425293, Accuracy = 0.7707701921463013
Training iter #1518000:   Batch Loss = 11.814190, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 15.655860900878906, Accuracy = 0.7853244543075562
Training iter #1520000:   Batch Loss = 11.538193, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 15.3125581741333, Accuracy = 0.785930871963501
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-3800
Training iter #1522000:   Batch Loss = 12.027887, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 15.086758613586426, Accuracy = 0.7810794711112976
Training iter #1524000:   Batch Loss = 11.342503, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 15.637313842773438, Accuracy = 0.7871437072753906
Training iter #1526000:   Batch Loss = 11.474298, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.846275329589844, Accuracy = 0.7956337332725525
Training iter #1528000:   Batch Loss = 11.674625, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 14.94729995727539, Accuracy = 0.7841115593910217
Training iter #1530000:   Batch Loss = 11.697902, Accuracy = 0.9640102982521057
PERFORMANCE ON TEST SET: Batch Loss = 14.926830291748047, Accuracy = 0.797452986240387
Training iter #1532000:   Batch Loss = 11.288391, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 15.124269485473633, Accuracy = 0.797452986240387
Training iter #1534000:   Batch Loss = 10.988157, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 15.156591415405273, Accuracy = 0.7901758551597595
Training iter #1536000:   Batch Loss = 12.666488, Accuracy = 0.9300000071525574
PERFORMANCE ON TEST SET: Batch Loss = 15.435367584228516, Accuracy = 0.7756215929985046
Training iter #1538000:   Batch Loss = 11.829420, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 15.553333282470703, Accuracy = 0.7580351829528809
Training iter #1540000:   Batch Loss = 11.359827, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 15.02383041381836, Accuracy = 0.7926015853881836
Training iter #1542000:   Batch Loss = 11.771112, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 15.081884384155273, Accuracy = 0.7798665761947632
Training iter #1544000:   Batch Loss = 11.352855, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 14.716769218444824, Accuracy = 0.8065494298934937
Training iter #1546000:   Batch Loss = 11.967843, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 15.012643814086914, Accuracy = 0.7962401509284973
Training iter #1548000:   Batch Loss = 11.327669, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.400237083435059, Accuracy = 0.8132201433181763
Training iter #1550000:   Batch Loss = 10.976605, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 14.627731323242188, Accuracy = 0.7835051417350769
Training iter #1552000:   Batch Loss = 11.093347, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 14.218507766723633, Accuracy = 0.8016979694366455
Training iter #1554000:   Batch Loss = 10.771029, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 14.318687438964844, Accuracy = 0.8156458735466003
Training iter #1556000:   Batch Loss = 10.683296, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 14.375104904174805, Accuracy = 0.7950273156166077
Training iter #1558000:   Batch Loss = 10.723682, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 14.563867568969727, Accuracy = 0.8029108643531799
Training iter #1560000:   Batch Loss = 11.020617, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.484235763549805, Accuracy = 0.7877501249313354
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-3900
Training iter #1562000:   Batch Loss = 11.344409, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 15.079259872436523, Accuracy = 0.7962401509284973
Training iter #1564000:   Batch Loss = 11.534996, Accuracy = 0.9768637418746948
PERFORMANCE ON TEST SET: Batch Loss = 15.150025367736816, Accuracy = 0.780472993850708
Training iter #1566000:   Batch Loss = 11.384556, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 15.037498474121094, Accuracy = 0.7865372896194458
Training iter #1568000:   Batch Loss = 11.172934, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 14.767488479614258, Accuracy = 0.791388750076294
Training iter #1570000:   Batch Loss = 11.038502, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 14.67866039276123, Accuracy = 0.7944208383560181
Training iter #1572000:   Batch Loss = 10.820487, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.80506706237793, Accuracy = 0.7865372896194458
Training iter #1574000:   Batch Loss = 10.892796, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.205798149108887, Accuracy = 0.7980594038963318
Training iter #1576000:   Batch Loss = 10.900938, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 14.707980155944824, Accuracy = 0.7822923064231873
Training iter #1578000:   Batch Loss = 10.762363, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 14.341809272766113, Accuracy = 0.7932080030441284
Training iter #1580000:   Batch Loss = 10.725630, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 14.351945877075195, Accuracy = 0.8016979694366455
Training iter #1582000:   Batch Loss = 11.117846, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 14.618535995483398, Accuracy = 0.7847180366516113
Training iter #1584000:   Batch Loss = 10.818298, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.359355926513672, Accuracy = 0.8089751601219177
Training iter #1586000:   Batch Loss = 10.555071, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 14.622659683227539, Accuracy = 0.7992722988128662
Training iter #1588000:   Batch Loss = 10.936028, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 14.230618476867676, Accuracy = 0.8059430122375488
Training iter #1590000:   Batch Loss = 10.464474, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 14.488371849060059, Accuracy = 0.7865372896194458
Training iter #1592000:   Batch Loss = 10.173132, Accuracy = 0.987500011920929
PERFORMANCE ON TEST SET: Batch Loss = 14.088861465454102, Accuracy = 0.7968465685844421
Training iter #1594000:   Batch Loss = 10.463743, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 14.369293212890625, Accuracy = 0.788356602191925
Training iter #1596000:   Batch Loss = 11.112164, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.456409454345703, Accuracy = 0.8010915517807007
Training iter #1598000:   Batch Loss = 10.887705, Accuracy = 0.9588689208030701
PERFORMANCE ON TEST SET: Batch Loss = 14.276199340820312, Accuracy = 0.7901758551597595
Training iter #1600000:   Batch Loss = 10.496246, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.39511775970459, Accuracy = 0.788356602191925
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-4000
Training iter #1602000:   Batch Loss = 10.776004, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.275588989257812, Accuracy = 0.8004851341247559
Training iter #1604000:   Batch Loss = 10.834484, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 14.138315200805664, Accuracy = 0.8071558475494385
Training iter #1606000:   Batch Loss = 10.756011, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.232446670532227, Accuracy = 0.7768344283103943
Training iter #1608000:   Batch Loss = 10.167395, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 14.08009147644043, Accuracy = 0.8138265609741211
Training iter #1610000:   Batch Loss = 9.959778, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 14.114750862121582, Accuracy = 0.797452986240387
Training iter #1612000:   Batch Loss = 10.187436, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.228484153747559, Accuracy = 0.7901758551597595
Training iter #1614000:   Batch Loss = 10.517538, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.960262298583984, Accuracy = 0.8004851341247559
Training iter #1616000:   Batch Loss = 10.295557, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.33794116973877, Accuracy = 0.8004851341247559
Training iter #1618000:   Batch Loss = 10.515357, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 14.5498046875, Accuracy = 0.7901758551597595
Training iter #1620000:   Batch Loss = 10.339979, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.486844062805176, Accuracy = 0.8010915517807007
Training iter #1622000:   Batch Loss = 10.704094, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 14.151817321777344, Accuracy = 0.8077622652053833
Training iter #1624000:   Batch Loss = 10.436117, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.318378448486328, Accuracy = 0.7956337332725525
Training iter #1626000:   Batch Loss = 10.349302, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.039634704589844, Accuracy = 0.8010915517807007
Training iter #1628000:   Batch Loss = 10.306204, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 14.076979637145996, Accuracy = 0.8065494298934937
Training iter #1630000:   Batch Loss = 10.273608, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 14.02686595916748, Accuracy = 0.7919951677322388
Training iter #1632000:   Batch Loss = 10.249825, Accuracy = 0.9691516757011414
PERFORMANCE ON TEST SET: Batch Loss = 14.10589599609375, Accuracy = 0.7968465685844421
Training iter #1634000:   Batch Loss = 10.281443, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.409049987792969, Accuracy = 0.791388750076294
Training iter #1636000:   Batch Loss = 10.397921, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.974252700805664, Accuracy = 0.8029108643531799
Training iter #1638000:   Batch Loss = 10.371013, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.116873741149902, Accuracy = 0.7950273156166077
Training iter #1640000:   Batch Loss = 11.199948, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.71774959564209, Accuracy = 0.791388750076294
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-4100
Training iter #1642000:   Batch Loss = 10.546757, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.380081176757812, Accuracy = 0.7901758551597595
Training iter #1644000:   Batch Loss = 10.462164, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 14.06934642791748, Accuracy = 0.8041236996650696
Training iter #1646000:   Batch Loss = 10.590140, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 14.287094116210938, Accuracy = 0.7944208383560181
Training iter #1648000:   Batch Loss = 10.195840, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.913516998291016, Accuracy = 0.7968465685844421
Training iter #1650000:   Batch Loss = 10.251925, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 14.080148696899414, Accuracy = 0.7919951677322388
Training iter #1652000:   Batch Loss = 9.967510, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.961712837219238, Accuracy = 0.8089751601219177
Training iter #1654000:   Batch Loss = 9.984312, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.7985200881958, Accuracy = 0.8029108643531799
Training iter #1656000:   Batch Loss = 10.338303, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.810476303100586, Accuracy = 0.805336594581604
Training iter #1658000:   Batch Loss = 10.042325, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.83613395690918, Accuracy = 0.8041236996650696
Training iter #1660000:   Batch Loss = 9.224650, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.858556747436523, Accuracy = 0.7889630198478699
Training iter #1662000:   Batch Loss = 10.115219, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.821250915527344, Accuracy = 0.8029108643531799
Training iter #1664000:   Batch Loss = 10.141442, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.879499435424805, Accuracy = 0.8065494298934937
Training iter #1666000:   Batch Loss = 10.059814, Accuracy = 0.9717223644256592
PERFORMANCE ON TEST SET: Batch Loss = 13.736335754394531, Accuracy = 0.8029108643531799
Training iter #1668000:   Batch Loss = 9.914190, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.624462127685547, Accuracy = 0.8101879954338074
Training iter #1670000:   Batch Loss = 9.814753, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.83950424194336, Accuracy = 0.8029108643531799
Training iter #1672000:   Batch Loss = 9.959138, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.738367080688477, Accuracy = 0.8144329786300659
Training iter #1674000:   Batch Loss = 10.027981, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.951313018798828, Accuracy = 0.7986658811569214
Training iter #1676000:   Batch Loss = 9.623249, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 13.954496383666992, Accuracy = 0.7919951677322388
Training iter #1678000:   Batch Loss = 9.900745, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.924542427062988, Accuracy = 0.805336594581604
Training iter #1680000:   Batch Loss = 9.868540, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.0573148727417, Accuracy = 0.8041236996650696
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-4200
Training iter #1682000:   Batch Loss = 10.042934, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.280996322631836, Accuracy = 0.7895694375038147
Training iter #1684000:   Batch Loss = 9.752092, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.78929328918457, Accuracy = 0.805336594581604
Training iter #1686000:   Batch Loss = 9.910234, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.851276397705078, Accuracy = 0.7992722988128662
Training iter #1688000:   Batch Loss = 9.629763, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.955522537231445, Accuracy = 0.811400830745697
Training iter #1690000:   Batch Loss = 9.647685, Accuracy = 0.9825000166893005
PERFORMANCE ON TEST SET: Batch Loss = 13.96699333190918, Accuracy = 0.799878716468811
Training iter #1692000:   Batch Loss = 10.071951, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.937165260314941, Accuracy = 0.8041236996650696
Training iter #1694000:   Batch Loss = 9.764225, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.954741477966309, Accuracy = 0.7980594038963318
Training iter #1696000:   Batch Loss = 9.999398, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.422653198242188, Accuracy = 0.8144329786300659
Training iter #1698000:   Batch Loss = 10.010910, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.708868026733398, Accuracy = 0.81685870885849
Training iter #1700000:   Batch Loss = 10.237980, Accuracy = 0.9614396095275879
PERFORMANCE ON TEST SET: Batch Loss = 13.834060668945312, Accuracy = 0.7938144207000732
Training iter #1702000:   Batch Loss = 9.989189, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 13.747007369995117, Accuracy = 0.8144329786300659
Training iter #1704000:   Batch Loss = 10.658097, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 14.226192474365234, Accuracy = 0.7847180366516113
Training iter #1706000:   Batch Loss = 10.961823, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 14.195655822753906, Accuracy = 0.8120072484016418
Training iter #1708000:   Batch Loss = 10.988809, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.40216064453125, Accuracy = 0.7986658811569214
Training iter #1710000:   Batch Loss = 10.883757, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 14.402746200561523, Accuracy = 0.8035172820091248
Training iter #1712000:   Batch Loss = 10.497498, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.198862075805664, Accuracy = 0.8010915517807007
Training iter #1714000:   Batch Loss = 10.682877, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.246500015258789, Accuracy = 0.7871437072753906
Training iter #1716000:   Batch Loss = 10.276184, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 14.045524597167969, Accuracy = 0.8083686828613281
Training iter #1718000:   Batch Loss = 10.492064, Accuracy = 0.9474999904632568
PERFORMANCE ON TEST SET: Batch Loss = 13.863740921020508, Accuracy = 0.8095815777778625
Training iter #1720000:   Batch Loss = 10.202979, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 14.201395034790039, Accuracy = 0.7938144207000732
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-4300
Training iter #1722000:   Batch Loss = 10.201340, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.917970657348633, Accuracy = 0.8211036920547485
Training iter #1724000:   Batch Loss = 9.971242, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 14.177017211914062, Accuracy = 0.7950273156166077
Training iter #1726000:   Batch Loss = 10.293329, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.006404876708984, Accuracy = 0.791388750076294
Training iter #1728000:   Batch Loss = 9.738411, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 14.138381958007812, Accuracy = 0.8029108643531799
Training iter #1730000:   Batch Loss = 10.202686, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 14.365022659301758, Accuracy = 0.7950273156166077
Training iter #1732000:   Batch Loss = 9.839833, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.058042526245117, Accuracy = 0.7701637148857117
Training iter #1734000:   Batch Loss = 10.434681, Accuracy = 0.9768637418746948
PERFORMANCE ON TEST SET: Batch Loss = 13.765809059143066, Accuracy = 0.8004851341247559
Training iter #1736000:   Batch Loss = 9.958533, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.866846084594727, Accuracy = 0.785930871963501
Training iter #1738000:   Batch Loss = 9.894337, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.642491340637207, Accuracy = 0.8083686828613281
Training iter #1740000:   Batch Loss = 9.805017, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.603299140930176, Accuracy = 0.8041236996650696
Training iter #1742000:   Batch Loss = 9.307568, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 13.80504035949707, Accuracy = 0.799878716468811
Training iter #1744000:   Batch Loss = 9.611606, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.538816452026367, Accuracy = 0.8211036920547485
Training iter #1746000:   Batch Loss = 10.251911, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.88023567199707, Accuracy = 0.8065494298934937
Training iter #1748000:   Batch Loss = 9.382885, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.755830764770508, Accuracy = 0.8023044466972351
Training iter #1750000:   Batch Loss = 8.987904, Accuracy = 0.987500011920929
PERFORMANCE ON TEST SET: Batch Loss = 13.761651039123535, Accuracy = 0.8041236996650696
Training iter #1752000:   Batch Loss = 9.765236, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.691230773925781, Accuracy = 0.8126137256622314
Training iter #1754000:   Batch Loss = 9.229186, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 14.001338958740234, Accuracy = 0.7944208383560181
Training iter #1756000:   Batch Loss = 9.956269, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.597002029418945, Accuracy = 0.8089751601219177
Training iter #1758000:   Batch Loss = 9.871386, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.89249038696289, Accuracy = 0.7986658811569214
Training iter #1760000:   Batch Loss = 9.652061, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 13.578651428222656, Accuracy = 0.8235294222831726
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-4400
Training iter #1762000:   Batch Loss = 9.939579, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.722091674804688, Accuracy = 0.8083686828613281
Training iter #1764000:   Batch Loss = 9.755982, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.566850662231445, Accuracy = 0.8023044466972351
Training iter #1766000:   Batch Loss = 9.898609, Accuracy = 0.9900000095367432
PERFORMANCE ON TEST SET: Batch Loss = 13.351218223571777, Accuracy = 0.8095815777778625
Training iter #1768000:   Batch Loss = 9.973614, Accuracy = 0.9665809869766235
PERFORMANCE ON TEST SET: Batch Loss = 13.52737045288086, Accuracy = 0.811400830745697
Training iter #1770000:   Batch Loss = 9.396533, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.458070755004883, Accuracy = 0.8138265609741211
Training iter #1772000:   Batch Loss = 9.529392, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.478387832641602, Accuracy = 0.799878716468811
Training iter #1774000:   Batch Loss = 9.389124, Accuracy = 0.9825000166893005
PERFORMANCE ON TEST SET: Batch Loss = 13.68174934387207, Accuracy = 0.8083686828613281
Training iter #1776000:   Batch Loss = 9.761103, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.579971313476562, Accuracy = 0.8071558475494385
Training iter #1778000:   Batch Loss = 9.802954, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.954486846923828, Accuracy = 0.7962401509284973
Training iter #1780000:   Batch Loss = 10.314495, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.881852149963379, Accuracy = 0.799878716468811
Training iter #1782000:   Batch Loss = 9.891905, Accuracy = 0.9900000095367432
PERFORMANCE ON TEST SET: Batch Loss = 13.822639465332031, Accuracy = 0.811400830745697
Training iter #1784000:   Batch Loss = 10.033924, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.770637512207031, Accuracy = 0.7986658811569214
Training iter #1786000:   Batch Loss = 9.702317, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 13.952702522277832, Accuracy = 0.8071558475494385
Training iter #1788000:   Batch Loss = 9.800566, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.651376724243164, Accuracy = 0.8144329786300659
Training iter #1790000:   Batch Loss = 9.984947, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.911113739013672, Accuracy = 0.780472993850708
Training iter #1792000:   Batch Loss = 9.427451, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 13.65634536743164, Accuracy = 0.8089751601219177
Training iter #1794000:   Batch Loss = 9.249832, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.523725509643555, Accuracy = 0.8071558475494385
Training iter #1796000:   Batch Loss = 9.669772, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.60893726348877, Accuracy = 0.8071558475494385
Training iter #1798000:   Batch Loss = 9.305175, Accuracy = 0.9825000166893005
PERFORMANCE ON TEST SET: Batch Loss = 13.571622848510742, Accuracy = 0.8077622652053833
Training iter #1800000:   Batch Loss = 9.333583, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.567737579345703, Accuracy = 0.8089751601219177
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-4500
Training iter #1802000:   Batch Loss = 9.938119, Accuracy = 0.9614396095275879
PERFORMANCE ON TEST SET: Batch Loss = 14.427157402038574, Accuracy = 0.768950879573822
Training iter #1804000:   Batch Loss = 9.550493, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.707326889038086, Accuracy = 0.7926015853881836
Training iter #1806000:   Batch Loss = 9.465584, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.742091178894043, Accuracy = 0.8150393962860107
Training iter #1808000:   Batch Loss = 9.604884, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.528853416442871, Accuracy = 0.8065494298934937
Training iter #1810000:   Batch Loss = 9.109812, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 13.54476547241211, Accuracy = 0.811400830745697
Training iter #1812000:   Batch Loss = 9.251642, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.520556449890137, Accuracy = 0.8126137256622314
Training iter #1814000:   Batch Loss = 9.487573, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.65740966796875, Accuracy = 0.7877501249313354
Training iter #1816000:   Batch Loss = 9.132716, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 13.422126770019531, Accuracy = 0.8211036920547485
Training iter #1818000:   Batch Loss = 9.086376, Accuracy = 0.9825000166893005
PERFORMANCE ON TEST SET: Batch Loss = 13.590938568115234, Accuracy = 0.8010915517807007
Training iter #1820000:   Batch Loss = 9.127083, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.505420684814453, Accuracy = 0.8101879954338074
Training iter #1822000:   Batch Loss = 9.457676, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.4234619140625, Accuracy = 0.8029108643531799
Training iter #1824000:   Batch Loss = 8.623205, Accuracy = 0.9825000166893005
PERFORMANCE ON TEST SET: Batch Loss = 13.460742950439453, Accuracy = 0.8156458735466003
Training iter #1826000:   Batch Loss = 9.004311, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.534769058227539, Accuracy = 0.7901758551597595
Training iter #1828000:   Batch Loss = 9.295544, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.49980354309082, Accuracy = 0.7980594038963318
Training iter #1830000:   Batch Loss = 9.115282, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 13.91090202331543, Accuracy = 0.7992722988128662
Training iter #1832000:   Batch Loss = 9.021336, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.39630126953125, Accuracy = 0.8107944130897522
Training iter #1834000:   Batch Loss = 8.901144, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.294055938720703, Accuracy = 0.8186779618263245
Training iter #1836000:   Batch Loss = 9.586823, Accuracy = 0.9871465563774109
PERFORMANCE ON TEST SET: Batch Loss = 14.41859245300293, Accuracy = 0.7828987240791321
Training iter #1838000:   Batch Loss = 10.202152, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 14.36512279510498, Accuracy = 0.7986658811569214
Training iter #1840000:   Batch Loss = 9.447740, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 14.186847686767578, Accuracy = 0.7901758551597595
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-4600
Training iter #1842000:   Batch Loss = 10.169305, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.985422134399414, Accuracy = 0.8016979694366455
Training iter #1844000:   Batch Loss = 9.293556, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 13.980605125427246, Accuracy = 0.811400830745697
Training iter #1846000:   Batch Loss = 9.952483, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 14.199854850769043, Accuracy = 0.785930871963501
Training iter #1848000:   Batch Loss = 10.113897, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 14.03420639038086, Accuracy = 0.8071558475494385
Training iter #1850000:   Batch Loss = 10.145133, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.637231826782227, Accuracy = 0.8016979694366455
Training iter #1852000:   Batch Loss = 9.719931, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.67024040222168, Accuracy = 0.8138265609741211
Training iter #1854000:   Batch Loss = 9.741321, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.559103012084961, Accuracy = 0.8198908567428589
Training iter #1856000:   Batch Loss = 9.730761, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.871792793273926, Accuracy = 0.8004851341247559
Training iter #1858000:   Batch Loss = 9.698995, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.619817733764648, Accuracy = 0.811400830745697
Training iter #1860000:   Batch Loss = 9.423820, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.523664474487305, Accuracy = 0.8144329786300659
Training iter #1862000:   Batch Loss = 9.266855, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.711904525756836, Accuracy = 0.791388750076294
Training iter #1864000:   Batch Loss = 9.454590, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.809229850769043, Accuracy = 0.8083686828613281
Training iter #1866000:   Batch Loss = 9.813269, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 14.000320434570312, Accuracy = 0.8192844390869141
Training iter #1868000:   Batch Loss = 9.643910, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 13.929231643676758, Accuracy = 0.8029108643531799
Training iter #1870000:   Batch Loss = 9.856621, Accuracy = 0.974293053150177
PERFORMANCE ON TEST SET: Batch Loss = 13.870783805847168, Accuracy = 0.811400830745697
Training iter #1872000:   Batch Loss = 9.363098, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.845256805419922, Accuracy = 0.7968465685844421
Training iter #1874000:   Batch Loss = 9.556802, Accuracy = 0.9825000166893005
PERFORMANCE ON TEST SET: Batch Loss = 13.791672706604004, Accuracy = 0.7932080030441284
Training iter #1876000:   Batch Loss = 10.008885, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 13.821349143981934, Accuracy = 0.8107944130897522
Training iter #1878000:   Batch Loss = 9.510283, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.768611907958984, Accuracy = 0.8047301173210144
Training iter #1880000:   Batch Loss = 9.490921, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 13.510366439819336, Accuracy = 0.8071558475494385
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-4700
Training iter #1882000:   Batch Loss = 9.510564, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.562443733215332, Accuracy = 0.8174651265144348
Training iter #1884000:   Batch Loss = 9.323961, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.362643241882324, Accuracy = 0.8132201433181763
Training iter #1886000:   Batch Loss = 9.577089, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.354612350463867, Accuracy = 0.8186779618263245
Training iter #1888000:   Batch Loss = 9.291749, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.747441291809082, Accuracy = 0.8029108643531799
Training iter #1890000:   Batch Loss = 8.981831, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.462076187133789, Accuracy = 0.8089751601219177
Training iter #1892000:   Batch Loss = 9.204781, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.511938095092773, Accuracy = 0.8071558475494385
Training iter #1894000:   Batch Loss = 8.986367, Accuracy = 0.9825000166893005
PERFORMANCE ON TEST SET: Batch Loss = 13.551595687866211, Accuracy = 0.7980594038963318
Training iter #1896000:   Batch Loss = 9.142609, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.647976875305176, Accuracy = 0.8029108643531799
Training iter #1898000:   Batch Loss = 9.292662, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.583468437194824, Accuracy = 0.8162522912025452
Training iter #1900000:   Batch Loss = 9.455339, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.73282241821289, Accuracy = 0.8107944130897522
Training iter #1902000:   Batch Loss = 9.072469, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.61925220489502, Accuracy = 0.7962401509284973
Training iter #1904000:   Batch Loss = 9.271772, Accuracy = 0.9691516757011414
PERFORMANCE ON TEST SET: Batch Loss = 13.849445343017578, Accuracy = 0.8071558475494385
Training iter #1906000:   Batch Loss = 9.442239, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.620287895202637, Accuracy = 0.7968465685844421
Training iter #1908000:   Batch Loss = 8.921582, Accuracy = 0.987500011920929
PERFORMANCE ON TEST SET: Batch Loss = 13.828763961791992, Accuracy = 0.7853244543075562
Training iter #1910000:   Batch Loss = 9.677985, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.3914794921875, Accuracy = 0.799878716468811
Training iter #1912000:   Batch Loss = 10.001427, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.743429183959961, Accuracy = 0.8029108643531799
Training iter #1914000:   Batch Loss = 9.555518, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.417516708374023, Accuracy = 0.8217101097106934
Training iter #1916000:   Batch Loss = 9.280286, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.337726593017578, Accuracy = 0.8047301173210144
Training iter #1918000:   Batch Loss = 9.286107, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.256510734558105, Accuracy = 0.7919951677322388
Training iter #1920000:   Batch Loss = 9.904728, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.547090530395508, Accuracy = 0.8029108643531799
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-4800
Training iter #1922000:   Batch Loss = 9.826177, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.57614803314209, Accuracy = 0.8071558475494385
Training iter #1924000:   Batch Loss = 9.385782, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.459102630615234, Accuracy = 0.7992722988128662
Training iter #1926000:   Batch Loss = 9.590029, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.57631778717041, Accuracy = 0.8095815777778625
Training iter #1928000:   Batch Loss = 9.392506, Accuracy = 0.987500011920929
PERFORMANCE ON TEST SET: Batch Loss = 13.624435424804688, Accuracy = 0.8023044466972351
Training iter #1930000:   Batch Loss = 9.383783, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.367003440856934, Accuracy = 0.805336594581604
Training iter #1932000:   Batch Loss = 8.885869, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 14.785111427307129, Accuracy = 0.7841115593910217
Training iter #1934000:   Batch Loss = 10.181338, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 14.04422378540039, Accuracy = 0.8016979694366455
Training iter #1936000:   Batch Loss = 11.177525, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.554725646972656, Accuracy = 0.7828987240791321
Training iter #1938000:   Batch Loss = 11.220747, Accuracy = 0.9537274837493896
PERFORMANCE ON TEST SET: Batch Loss = 14.014317512512207, Accuracy = 0.8010915517807007
Training iter #1940000:   Batch Loss = 10.466990, Accuracy = 0.949999988079071
PERFORMANCE ON TEST SET: Batch Loss = 14.337380409240723, Accuracy = 0.7901758551597595
Training iter #1942000:   Batch Loss = 10.504627, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.670171737670898, Accuracy = 0.8059430122375488
Training iter #1944000:   Batch Loss = 10.767029, Accuracy = 0.9449999928474426
PERFORMANCE ON TEST SET: Batch Loss = 13.77678108215332, Accuracy = 0.7932080030441284
Training iter #1946000:   Batch Loss = 9.890189, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.58858871459961, Accuracy = 0.8059430122375488
Training iter #1948000:   Batch Loss = 9.901899, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.580337524414062, Accuracy = 0.7938144207000732
Training iter #1950000:   Batch Loss = 10.400724, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.61367416381836, Accuracy = 0.797452986240387
Training iter #1952000:   Batch Loss = 9.487745, Accuracy = 0.9850000143051147
PERFORMANCE ON TEST SET: Batch Loss = 13.583786010742188, Accuracy = 0.7822923064231873
Training iter #1954000:   Batch Loss = 9.744431, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.646056175231934, Accuracy = 0.8059430122375488
Training iter #1956000:   Batch Loss = 10.181374, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.658143997192383, Accuracy = 0.7992722988128662
Training iter #1958000:   Batch Loss = 9.949347, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.562578201293945, Accuracy = 0.7986658811569214
Training iter #1960000:   Batch Loss = 9.617361, Accuracy = 0.9674999713897705
PERFORMANCE ON TEST SET: Batch Loss = 13.4999418258667, Accuracy = 0.8047301173210144
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-4900
Training iter #1962000:   Batch Loss = 9.683622, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 13.634958267211914, Accuracy = 0.7980594038963318
Training iter #1964000:   Batch Loss = 9.633820, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 13.583643913269043, Accuracy = 0.785930871963501
Training iter #1966000:   Batch Loss = 9.704021, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.322070121765137, Accuracy = 0.8071558475494385
Training iter #1968000:   Batch Loss = 9.307249, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 13.465867042541504, Accuracy = 0.7938144207000732
Training iter #1970000:   Batch Loss = 9.242065, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.404119491577148, Accuracy = 0.8016979694366455
Training iter #1972000:   Batch Loss = 9.167217, Accuracy = 0.9768637418746948
PERFORMANCE ON TEST SET: Batch Loss = 13.396356582641602, Accuracy = 0.8107944130897522
Training iter #1974000:   Batch Loss = 9.280743, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.411754608154297, Accuracy = 0.7956337332725525
Training iter #1976000:   Batch Loss = 8.772442, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.447129249572754, Accuracy = 0.805336594581604
Training iter #1978000:   Batch Loss = 9.603601, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.420546531677246, Accuracy = 0.7877501249313354
Training iter #1980000:   Batch Loss = 9.153947, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.498308181762695, Accuracy = 0.8035172820091248
Training iter #1982000:   Batch Loss = 9.089342, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.455978393554688, Accuracy = 0.805336594581604
Training iter #1984000:   Batch Loss = 9.012656, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.373201370239258, Accuracy = 0.7956337332725525
Training iter #1986000:   Batch Loss = 9.482963, Accuracy = 0.9574999809265137
PERFORMANCE ON TEST SET: Batch Loss = 13.400718688964844, Accuracy = 0.8047301173210144
Training iter #1988000:   Batch Loss = 9.070308, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.740594863891602, Accuracy = 0.7871437072753906
Training iter #1990000:   Batch Loss = 11.552884, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 15.841585159301758, Accuracy = 0.805336594581604
Training iter #1992000:   Batch Loss = 10.887024, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 14.980450630187988, Accuracy = 0.7956337332725525
Training iter #1994000:   Batch Loss = 10.211360, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 14.081433296203613, Accuracy = 0.799878716468811
Training iter #1996000:   Batch Loss = 9.749722, Accuracy = 0.9750000238418579
PERFORMANCE ON TEST SET: Batch Loss = 14.36151123046875, Accuracy = 0.7786537408828735
Training iter #1998000:   Batch Loss = 10.225018, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 13.78547477722168, Accuracy = 0.8126137256622314
Training iter #2000000:   Batch Loss = 9.749443, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 14.21960735321045, Accuracy = 0.7841115593910217
Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-5000
Training iter #2002000:   Batch Loss = 9.940218, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.660634994506836, Accuracy = 0.8059430122375488
Training iter #2004000:   Batch Loss = 10.018943, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 14.249513626098633, Accuracy = 0.7762280106544495
Training iter #2006000:   Batch Loss = 9.616116, Accuracy = 0.9871465563774109
PERFORMANCE ON TEST SET: Batch Loss = 14.049055099487305, Accuracy = 0.8041236996650696
Training iter #2008000:   Batch Loss = 10.183842, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 14.007222175598145, Accuracy = 0.805336594581604
Training iter #2010000:   Batch Loss = 10.011344, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 14.12977123260498, Accuracy = 0.7926015853881836
Training iter #2012000:   Batch Loss = 10.203449, Accuracy = 0.9599999785423279
PERFORMANCE ON TEST SET: Batch Loss = 14.155006408691406, Accuracy = 0.7780473232269287
Training iter #2014000:   Batch Loss = 9.562605, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 14.133858680725098, Accuracy = 0.7901758551597595
Training iter #2016000:   Batch Loss = 10.003766, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.621713638305664, Accuracy = 0.8132201433181763
Training iter #2018000:   Batch Loss = 9.210215, Accuracy = 0.9825000166893005
PERFORMANCE ON TEST SET: Batch Loss = 13.982795715332031, Accuracy = 0.7671315670013428
Training iter #2020000:   Batch Loss = 9.917272, Accuracy = 0.9524999856948853
PERFORMANCE ON TEST SET: Batch Loss = 13.614635467529297, Accuracy = 0.8023044466972351
Training iter #2022000:   Batch Loss = 10.088202, Accuracy = 0.9624999761581421
PERFORMANCE ON TEST SET: Batch Loss = 13.729340553283691, Accuracy = 0.7877501249313354
Training iter #2024000:   Batch Loss = 9.390543, Accuracy = 0.9800000190734863
PERFORMANCE ON TEST SET: Batch Loss = 13.555318832397461, Accuracy = 0.8035172820091248
Training iter #2026000:   Batch Loss = 9.608966, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.43596363067627, Accuracy = 0.8035172820091248
Training iter #2028000:   Batch Loss = 9.829031, Accuracy = 0.9549999833106995
PERFORMANCE ON TEST SET: Batch Loss = 13.850135803222656, Accuracy = 0.788356602191925
Training iter #2030000:   Batch Loss = 9.058367, Accuracy = 0.9775000214576721
PERFORMANCE ON TEST SET: Batch Loss = 13.614805221557617, Accuracy = 0.7962401509284973
Training iter #2032000:   Batch Loss = 9.795065, Accuracy = 0.9649999737739563
PERFORMANCE ON TEST SET: Batch Loss = 13.55874252319336, Accuracy = 0.8132201433181763
Training iter #2034000:   Batch Loss = 9.168276, Accuracy = 0.9700000286102295
PERFORMANCE ON TEST SET: Batch Loss = 13.893083572387695, Accuracy = 0.785930871963501
Training iter #2036000:   Batch Loss = 9.044746, Accuracy = 0.9725000262260437
PERFORMANCE ON TEST SET: Batch Loss = 13.15104866027832, Accuracy = 0.8126137256622314
Optimization Finished!
FINAL RESULT: Batch Loss = 13.10367202758789, Accuracy = 0.8156458735466003
All train time = 18273.819661855698
Final Model saved in file: ./lstm2/model_mergeall_kfold1.ckpt-final/home/sunrepe/anaconda3/lib/python3.7/site-packages/matplotlib/font_manager.py:1241: UserWarning: findfont: Font family ['Times New Roman'] not found. Falling back to DejaVu Sans.
  (prop.get_family(), self.defaultFamily[fontext]))

Precision: 83.04128345516243%
Recall: 81.56458459672528%
f1_score: 81.49687254371383%

Confusion Matrix:
[[146   0   0   0   0   0   9   9   0   1]
 [  0 161   0   0   0   0   1   0   1   2]
 [  0   0 132   0   0   0  15   1  17   0]
 [  1   0  16  98   0   0   0  32  13   4]
 [  0   0   0   0 165   0   0   0   0   0]
 [  0   0   6   0   0 154   0   0   5   0]
 [  3   0   0   0   0   0 153   3   6   0]
 [  2   0   3   7   0   0  39  97  13   5]
 [  0   0  72   0   0   0   4   0  88   0]
 [  4  10   0   0   0   0   0   0   0 151]]

Confusion matrix (normalised to % of total test data):
[[ 8.85385     0.          0.          0.          0.          0.
   0.54578537  0.54578537  0.          0.06064281]
 [ 0.          9.763494    0.          0.          0.          0.
   0.06064281  0.          0.06064281  0.12128562]
 [ 0.          0.          8.004851    0.          0.          0.
   0.9096422   0.06064281  1.0309278   0.        ]
 [ 0.06064281  0.          0.970285    5.942996    0.          0.
   0.          1.94057     0.78835654  0.24257125]
 [ 0.          0.          0.          0.         10.006064    0.
   0.          0.          0.          0.        ]
 [ 0.          0.          0.36385688  0.          0.          9.338994
   0.          0.          0.30321407  0.        ]
 [ 0.18192844  0.          0.          0.          0.          0.
   9.27835     0.18192844  0.36385688  0.        ]
 [ 0.12128562  0.          0.18192844  0.42449972  0.          0.
   2.3650696   5.882353    0.78835654  0.30321407]
 [ 0.          0.          4.366283    0.          0.          0.
   0.24257125  0.          5.336568    0.        ]
 [ 0.24257125  0.60642815  0.          0.          0.          0.
   0.          0.          0.          9.157064  ]]
Note: training and testing data is not equally distributed amongst classes, 
so it is normal that more than a 6th of the data is correctly classifier in the last category.
